A focused engineer is a performant engineer and a focused agent is a performant agent. Context engineering is the name of the game for high value engineering in the age of agents. So how good are your context engineering skills? Do you have a skill issue? Let's find out and fix it.

out and fix it. There are three levels of context engineering and a fourth hidden level if you're on the bleeding edge pushing into agentic engineering. But first we have to ask, why are context engineering techniques so important? It's because context engineering enables you to manage the precious and delicate resource that is the context window of your agents like Claude Code. There are only two ways to manage your context window, R and D. Let's break down each

Let's break down each technique at each level and use the R&D framework to maximize not what you can do, but what your agents can do for you. A huge focus in TAC is scaling up the intelligence we can deploy both in the loop and out the loop. But with every agent we create, we must adopt their perspective to maximize their impact context is a critical in-agent leverage point that

in-agent leverage point that determines how an agent performs at any given task there's a sweet spot a range of context where your agent performs to its maximum possible capability for the task at hand as you scale up to hundreds and thousands of agent executions hitting this sweet spot consistently becomes even more important and we do that with context engineering we obsessively manage the context going in our agents. We adopt our agents perspective to gain an awareness

to gain an awareness of the state of our agents inside of our agentic pipelines, inside of our ADWs. When aligned with the right model prompt pools and the right range of context, we can hit the core four bullseye over and over and over. This directly increases our agentic coding KPIs we break down in tech and our KPIs directly tell us if we're improving our agentic coding capabilities. Adding the right context to your agent is usually the

agent is usually the easy part. The real trick is finding the context agentically and then removing and delegating context so that it doesn't end up creating context rot and context bloat. Search and destroy is the real skill in context engineering, and we can do this better than anyone with the R&D framework. When you boil it down, there are only two ways to manage your context window, R and D. reduce and delegate. Every technique we'll break down right now fits into

right now fits into one or both of these buckets. Let's start at the beginner level and move up to more technical levels of context engineering. Your agent's context window is a precious, renewable, but limited temporal resource. What does that mean? The context window is ephemeral. It resets. It's alive for only a certain amount of time and the state in your context window is critical to your success. Whenever you have a resource that determines your success, you must measure it so

must measure it so you can improve it. The context window is the single most important leverage point for effective agentic coding. So how do we measure it? Inside of the elite context engineering codebase, we can break down how exactly we'll measure our context in our Claude Code agents. We have two primary modes of measuring context, context in our agent and context we might add to our agent. If we spin up a Claude Code instance, you can see here we have some context problems

have some context problems already that we'll work through. You can type slash context and see all the context in our agent's context window. This is your most important tool for measuring and therefore managing your context window. It shows you exactly how much stuff your agent will work through with every prompt execution. You can see here we are absolutely torching or clawed opus tokens. We have 63K tokens already spent on boot up. If you never run slash context, you will not

context, you will not find this information and you will not know that we've already spent 31% of our available context window. Our second mechanism for understanding context is token counters. In the bottom right of my instance here, you can see I have a token counter counting the number of tokens highlighted and in the file. We have 2,600 tokens available in the README. So anytime our agent interacts with the README, which is a high touch point for agents, they'll consume 2000

agents, they'll consume 2000 tokens if they read the entire file. Measuring your context is foundational. Every context engineering technique we build from here depends on this. If you aren't actively paying attention to the state of your agent's context, you're just vibe coding and you'll only be able to tackle the lowest hanging fruit, which is already a massively saturated space. To push further, you must learn to see from your agent's perspective. What gets measured gets managed. So measure your context window. Use slash context and

Use slash context and install a tokenizer right in your IDE so you know what's coming into your agent's context. Do not load MCP servers unless you need them. Take a look at how much of my Claude Code Opus tokens are being chewed up by MCP tools. 24.1 thousand tokens. Okay, this is 12% of the entire available context window, it's very likely

you're wasting tokens with MCP servers you're not actively using. This is a simple, easy beginner context engineering mistake to make. Thankfully, the solution is simple. Be very purposeful with your MCP servers. If we open up the directory here, you can see we have a variety of MCP servers. Inside of the .mcp.json file, we have a bad practice of context engineering inside of this codebase. We have a default .mcp.json file that is always loading into the context window of our

context window of our agents. Just for MCP servers, it's consuming 24K tokens. Let's round down, that's 10% of our entire 200K token context window, chewing up expensive, valuable Claude Opus tokens. You might have a model in the future, regardless of your model, context management is still critically important. 10K tokens is 5% of your entire 200K context window. This means 5% less work you can do with this swing of

with this swing of your agent. And if you boot up five agents over an hour, that's 25% of a context window in total, completely wasted, okay? Unless you're always using every single MCP server, which I highly doubt, okay? As you can see, these numbers will stack up against you very quickly. The first thing I recommend doing is get rid of this.mcp.json. Just completely delete this thing. Okay, don't use a default.mcp.json for your codebase. All right, and why is that? It's because right away clears up our context

clears up our context window, okay? If we type Claude now context, we've just saved some 20,000 tokens by not preloading any MCP servers, okay? Do not assume you need these. If you do need these, I recommend you fire these up by hand. The cracked Claude Code team at Anthropic has a couple of quick, simple, easy command line flags you can use. Cloud dash dash MCP config, and now you just pass in the config you want. So let's say I just wanted the Firecrawl MCP server. You can see I have this specialized file here that pulls in just the Firecrawl

in just the Firecrawl MCP server, and I've self fixed it with 4K. So I know exactly how many tokens are going to get consumed by default every time. Okay, so I can copy the path to this, paste that there. And if you do have some globals that you wanna overwrite, you can use dash dash strict MCP config, and then you can fire this off and check this out. When we run slash context, we're only going to get that 6K tokens strictly from the Firecrawl MCP server. And now we can kick off this specialized agent focused

this specialized agent focused on just this one MCP server, all right? And if you do need every single MCP server, explicitly reference it, be very conscious with the state going into your context window. There are many places to be wasteful as an engineer, to move fast and break things. The context window of your agents is not one of them. Here, we are of course using the R in the R and D framework. We are reducing. So you might think this is not a big deal, but you have to think about every single agent instance you

single agent instance you boot up. Okay, we're talking about tens and hundreds. And as you scale up, this bad practice will bleed into your leverage points of agentic coding. Okay, they scale all the way in, your ADWs. Only use these MCP servers when you explicitly need them because they come with a cost. This technique is a bit controversial, especially for beginners, but I strongly recommend context priming over using a claw.md or any

a claw.md or any similar auto loading memory file. While this seems convenient at first, it creates problems as you scale your agentic coding across different tasks. So what is context priming? and why is it superior to a memory file? And why is it superior to claw.md? Let's first double click into claw.md. There's nothing inherently wrong with this file. Like most technology, it's how it's used that's the problem. If we boot up a new instance here, you can see right away

we have this error message. Let's address this now, okay? We have built up a massive, and I mean massive, claw.md file. If we run slash context once again and monitor what's going on here, we have cleaned up our MCP servers, but we haven't cleaned up is this massive memory file. We have a 23,000 token memory file, again, showing up about 10% of our entire context window of expensive Opus tokens. I'm of course exaggerating my claw.md file here just to showcase

here just to showcase this idea, but I can almost guarantee you there's an engineer out there somewhere with a claw.md file that is, you know, 3,000 lines long. And why is that? It's because they and their team, they've just constantly added additional items to their memory over and over and over again until it's become what it is now. Okay, a massive glob of mess, okay? Even the claw code engineers built in a warning here for us. Large claw.md will impact performance What they're really

performance What they're really saying here is There's a big chunk of state in the context window that will likely change the outcome and deter it from the outcome you're looking for. The claw.md file is incredible for one reason. It's a reusable memory file that's always loaded into your agent's context window. Simultaneously, a claw.md file is terrible for the exact same reason. It's a reusable memory file that's always loaded into your agent's context window. So why is that a problem? The problem with always on

problem with always on context is that It's not dynamic or controllable. Engineering work inside of codebases constantly changes, but the claw.md file only grows. Over time, as you and your team add more information, the file grows and grows, and eventually it becomes bloated with context that isn't relevant to every engineering task, and this is the key. Eventually, it's not gonna be relevant for the work you're doing. It's going to have useless context in your precious context window, and in the worst case, it's gonna have contradictory information

gonna have contradictory information inside of your context window. That is the worst possible case, and this will happen if you just keep growing your memory file. All right, so what's the solution here? The solution is context priming. Let's trim down, right? Let's use this flaw.concise, right? It's a lot simpler. It's something that we always want to add, you know, and take a look at this, right? It's only 43 lines and it's just got some, you know, mock structure for this codebase. And these are just some things that we always want every single agent to

every single agent to have, okay? I have to keep stressing that because this is the reality of the memory file. It will always be added. So copy this, we'll clean this up, save that, resetter agent here, CLD is an alias. You can check out all the aliases I'm gonna run throughout this lesson. At the bottom of the readme, you can see all the aliases right here. All right, so now we have a concise MD file. The warning is gone. We can type slash context and check this out. Our context window on boot up on startup

boot up on startup is looking Much, much better, 92% free. What's left, right? Our small memory file is down to 0.2%, right? 350 tokens, this is great. This is a clear focus agent. Now, what do we use instead of this large memory file? We should context prime. What does that mean? Let me show you, slash prime, and we hit enter. Context priming is when you use a dedicated reusable prompt, AKA a custom slash command, to set up your agent's initial context window specifically for

context window specifically for the task type at hand. So with every codebase, I always set up Claude commands You can see here we have two prime commands in this code base. Priming is just a reusable prompt. We can take a look at this right here. It's very simple. It has a concise structure where we have the purpose, we have our run step, we have a read step and a report step. Okay, now our agent is ready to go. So it's read a couple files, it's read the readme, it understands the structure of the code

structure of the code base. And now if we type context, our agent, has a little bit of information about this codebase for this specific problem set. And so this problem set is of course, just getting a general understanding of our code base. So instead of relying on a static always loaded memory file, we're using context priming to gain full control over the initial context of our agents. This is very powerful. Unlike the memory file, we can prime against several different areas of focus

different areas of focus in our codebase. Okay, so imagine a you know, prime bug command, right? For bug smashing, imagine a prime chore or prime feature, or like we have in this codebase, prime CC, okay? This is a focused prompt. It's our hot loading memory file for operating with Claude code and updating the Claude code files inside of this codebase, okay? And so, you know, you can see it looks very similar. We're actually running the base prime command right from the prime CC command to

prime CC command to where we're stacking prompts to better manage our context window. And then you can see here, we're just saying read a couple extra files and do the same thing, report your understanding of the codebase. Even with this small example, elite context engineering codebase, there's already room for specialization. Are we working on the app level or are we working on the Claude agent level, right? And as you know from tech, we are talking here whenever we're working on the agents, we're talking about the agentic layer, right? We're working on the agentic

working on the agentic layer. We're building the system that builds the system. So prime, right? Don't default. Your claw.md file should be shrunk to contain only the absolute universal essentials that you're 100% sure you want loaded 100% of the time. You see how powerful that conditional is and how strict that conditional is? So be very careful with these memory files, keep them slim, and instead prefer context priming. This way you can build up many areas of focus for your agents.

focus for your agents. And if you find yourself coming back to some specific area of focus, build out a prime command for that specific area of focus for you and your team. This is the beginning of a big agentic level technique that we're gonna talk about in this lesson. You can see we have this new experts directory. We'll talk about that at the end of this lesson. So now we enter the intermediate zone. Let's enter the intermediate zone of context engineering and talk about

engineering and talk about controlling your output tokens. Output tokens are nearly always the most expensive part of your agent. Output tokens are priced anywhere from three to five X the price of your input tokens. That means one right costs you up to five times more output tokens burn your compute and therefore burn a hole in your wallet fast. Thankfully, We can micromanage this just a little bit with output styles to limit and specify the types of

specify the types of output you want Cloud Code to have and therefore the number of output tokens CloudCode will generate when responding. Now it's important to note a lot of the output tokens are chewed up when you're actually writing and generating files and when CloudCode is returning large chunks back to you, there's not a lot you can do about this, but we can control the responses CloudCode has directly to you. Now we can showcase that with a CloudCode settings file. So inside of our dot Claude directory here, we have settings dot

we have settings dot local dot concise. All right, so I'm gonna copy the path to this and you can see it has an output style specified, okay? It has a one word output style, right? So let's see how powerful this can be. Claude in Yolo mode with Sonnet, specify a settings file right here and kick this off. Now we'll just type something simple here, we'll just say hi and then we'll open up another terminal side by side and type Claude. So you can see here our agent just said done. Okay, so it's not interested in talking to us. It's

talking to us. It's not interested in chewing up output tokens. Now here on the right side, if we type output styles, you can see we're running the default. And let me actually go ahead and get this in YOLO mode here as well, running the Sonnet model. Output styles here, we have default. And if we say hi here, we're of course gonna get a normal response coming out of cloud code, okay? So right away with just a high, we are getting a massive difference in output tokens, okay? And keep in mind, these are output tokens, right? Let's kick this up, right? Let me show you the scale in

you the scale in which this is important. Let's run a classic prompt. What does this codebase do? And I'm gonna copy that. kick it off here, kick it off here. So these are both the sonnet models. They're both going down their non-deterministic path. Here is our verbose on the right, and here is our one word on the left. So again, just take note of the difference here, right? And let's go ahead and run slash context on the left, slash context on the right. And let's just briefly look at the output tokens here. So we can see there's no

can see there's no difference in token usage yet. In fact, our concise agent has actually spent a few more tokens reading in and looking for files. Okay, let's keep pushing this and get out of the non-deterministic nature, right? Let's find the average here. Okay, I'm gonna fire this off here and I'm gonna fire this off here, okay? And so what we're doing here is we're reading some documentation in AI docs. We can pull this up right here. It's Claude Code, TypeScript SDK documentation, and we're letting our agents just kick off and run side by side, all right? And the important thing to pay attention to here is the response of our

the response of our one word output style versus our default cloud code style they're both going to do the same work they're both going to complete and generate this new file right here but the difference and the output and the difference and the consumption of tokens specifically the output tokens is going to be larger and we can look at this output style exactly concise done check this out so we have a you know list here of output styles and you can see here we are continuously reiterating this clock code output style

clock code output style to just say done There are of course a couple exceptions to this. We don't always just want a point blank done response. If we ask our agent a question or something goes wrong, we of course want a more written out response. But most of the time when our agent is shipping work successfully, all it needs to do is respond with done, which is what we're gonna see here in just a second. So you can see on the right side, our agent has completed and it's reported these output tokens to us here. And on the left side here, when our agent finishes, it's going

agent finishes, it's going to just report Done. It's not giving us any extraneous, extra detail, verbose information. We know exactly what we asked. Just tell us if it was successful or if it failed. Okay? And so, you know, this might seem like a small thing. What I want to do is just showcase this simple idea so that you can understand at scale how important this is. Okay? So we'll paste this in. And of course, we can monitor our token usage. We can see point blank, this one response coming out of cloud code consumed 150 output tokens, okay? Not too

tokens, okay? Not too bad, right? Now, if we open up a new file and copy done, all right, let's copy just done. And we'll actually put this on the left and we'll put this on the right. You can see here we have two tokens, all right? So it's not the fact that this is a ton of tokens, it's not, but it's the fact that this is two tokens and this is 150 tokens. When we're running Outlook agents, as we start to get out the loop, we don't need to be chewing up this 150 extra tokens across tens of prompts,

across tens of prompts, across hundreds of prompts and hundreds of agents, okay? Every piece of context matters. When you look at a graph of this stuff, when you start to see your token consumption, you know this to be true, okay? We have reduced our token token usage here in this one element of Cloud Code down from 150. This is some massive 99% reduction in token usage, okay? And it's all because we are controlling the output style of Claude Code with a concise done prompt.

a concise done prompt. There are other versions of this. You can find some better middle ground, but you can see very quickly how this is gonna stack up and this is a great way to conserve your token usage. Now, it's also important to note here that output styles do something interesting to the Cloud Code instance you're running. It effectively swaps the output style block in the system prompt, right? It hot swaps the output style block in the system prompt of Claude Code. This is an interesting trend. Keep your eye on this. We're gonna talk about the future of context

the future of context engineering at the end of this lesson, some potential future directions that you can bet on. Let's go ahead and close our agents and move on to a big idea, a popular idea in the world of Claude Code. Let's talk about sub-agents. Now, it's not just about using sub-agents. This is about using sub-agents properly. When you use Cloud Code sub agents, you are effectively creating a partially forked context window. Let's create a cloud instance here. If we type context in an

type context in an agent, a brand new agent, you'll notice something really interesting. We have custom agents here. All right, we have three custom agents that we can use at any point in time. We can, of course, find these inside of Cloud Code. Under the agents directory, we can look at any one of these, right? Now you'll notice something quite interesting. All of our agents here, our custom agents only consume 122 tokens. Whereas you can see my rough token counter is looking at 900 for this one agent. What's going on here? What's the big difference? The big difference here is that when you're

is that when you're working with sub agents, you are working with system prompts, okay? There is a massive difference between the system prompt and a user prompt, right? When you're prompting Claude Code, you're writing user prompts when you're building reusable custom slash commands, you're writing a user prompt that all gets passed right into the agent. This is a system prompt, which is nice because it means that it's not directly added to our primary agents context window. Okay. And this advantage of sub agents continues with clock of sub

with clock of sub agents. We can delegate work off of our primary agents context window. This is a massive point for the D and the R and D framework, right? It's delegation. We are keeping context out of our primary agents context window. For example, we can run slash load AI docs. And so this is going to load AI documentation from our AI docs readme. It's gonna read through all of these items. We can load up the AI docs reusable prompt and it's going to kick off sub agents

kick off sub agents to do this work for us. So our primary agents reading this file and it's gonna kick off however many agents we need to to fetch every one of our AI doc URLs, right? So it looks like, I don't know, what do we have here, 10 or 11? You can see this is gonna get kicked up here pretty soon after we do a date check on any file here that's old than 24 hours, which I think all of them are at this point. And so you can see it's removing these and then it's going to fire up these agents to reload our AI docs. There it is, doc scraper. And this is critical, right? A web scrape can consume quite

scrape can consume quite a bit of tokens. And so we have this load AI docs, reusable agentic prompt that's gonna kick this off. You can see that the token's starting to tick up. We already have 3K for each agent. This is 3K tokens times eight or 10 that isn't added to our primary agent. This is sub-agent delegation. We're leveraging the context windows of our sub-agents to do work and keep it out of our primary agent. In this case, this is a great use case

a great use case for sub-agents. We have this workflow where Dock Scraper, You know, we have this system prompt here that details exactly how to web scrape with Firecrawl or Webfetch, right? Whatever web scraping tool you wanna use, it has it here. This would be a good example for us to fire up and load that one MCP server. But now these agents are just going to run the scrape, which will consume their context window. And then they're going to write the output files, right? So now we should see refreshed AI docs

see refreshed AI docs written here. Yup, there they are. And there it is. Yeah, there's our success command here. We of course are using a great prompt structure. If we go back to load AI docs and collapse here, you can see we're using a classic agentic prompt workflow format where we have the purpose, variables, workflow and report format, definitely check out the agentic prompt engineering extended lesson to learn all of the powerful prompt structures you can use inside of both your system prompts and your user prompts like this. This is a

this. This is a classic workflow we use a lot throughout TAC and throughout our extended lessons. So you can see here all the tokens that were not added to my primary agents context window. We can of course slash context to prove that we're only up to 9K tokens, okay? We delegated work, right? We're stepping into the D in the R and D framework. There's only two ways to manage your context window, reduce context, entering your primary agent and delegate context to sub-agents and as you'll see in upcoming techniques to other primary

techniques to other primary agents. CloudCo sub-agents have limitations. Sub-agents sit at the intermediate level for a reason because instead of keeping track of just one set of context model prompting tools, the core four, we now have to keep track of as many as you spawn sub-agents. So it becomes super important to isolate the work that your sub-agents are doing into one concise prompt to one focused effort. Remember, a focused agent is a performant agent. Sub-agents are also a little trickier because of the flow

because of the flow of information. The flow of information in these multi-agent systems is critical. Your primary agent, is prompting your sub-agents and your sub-agents are responding not to you but back to your primary agent. So once we start getting into this intermediate, advanced, and agentic level, we have to keep track of every agent's core four that we spin up. If you're losing track of a single agent, right, and you have a bunch of wasted context, you probably aren't yet ready for sub-agents. You

ready for sub-agents. You probably want to spend some more time cleaning up, managing, and maintaining clean context windows for your existing single primary agent. But once you're ready, sub agents are a great intermediate level, a great intermediate technique to step into because you can delegate the entire context window to one or more sub agents. As you saw here, we say probably 40,000 total tokens and ran all this work much faster than it would have taken a single primary agent. So next up, we have a powerful classic pattern.

a powerful classic pattern. We're continuing to push into the delegation side of the R&D framework. You can have two agents working side by side. One agent plans, the other agent executes the plan. You have a planner and a builder, an architect and an editor. This is a classic prompt chaining technique that expands and extrapolates very well into the age of agents with your Claude Code agents and with any agent. We have a reusable prompt in this

reusable prompt in this codebase called Quick Plan. All right, and all it does is if we open up a quick plan, this accepts a single argument, which is the user prompt. Inside of TAC, you're very familiar with this pattern. We built out and extrapolated on this in the software developer lifecycle for the plan phase, but quick plan is roughly the same idea. You have a single prompt that's focused on just planning. So let's plan some work, right? Let's push that Claude Code TypeScript SDK a little bit further and create a small reusable codebase

small reusable codebase inside of our application layer. So app slash CCTS wrapper. Okay, so let's fire that off this agent. is only going to plan. And now, as you can imagine, if our agent on the left is only planning, we have a completely free context window on the right to build. Okay. And so we of course have slash build. We can then take this build command and execute it on the plan generated by our plan agent. So we're going to let this agent cook. And as you can see, we are continuing to reduce context

continuing to reduce context windows and delegate work between agents. The idea here is simple. Separate your agents responsibilities. Why? Because especially for your implementer, AKA your editor and builder agent, you want their context focused so they can make surgical perfect error free edits. A lot of engineers are stacking up a chat window. They're prompt chaining inside of a single agents chat window over and over and over. And they're not realizing that they're

not realizing that they're causing context rot and context bloat with every prompt that isn't laser focused to the task at hand. With our planning prompt, we have a detailed prompt in our classic instruction prompt format. Again, check out a Genetic Prompt Engineering extended lesson on the powerful prompt structures that you can write. And we're being very, very clear about what it needs to do. We're planning work. and we're planning work with a powerful Opus agent. Again, if you're in the future, I hope you

future, I hope you have better, more powerful models, use that. These techniques are all the same across models. Don't get stuck up on any one individual model, but you can see here our planner has finished planning. Now we can just copy this and we can be very confident that whatever is in here is up to par with our standards because we've put upfront investment into our planning phase. So I can just copy the reference to this and go to our build agent, paste this in, and with no context priming at all, everything the build agent needs is inside of

needs is inside of this plan. It's all there because our planner took care of that for the builder, all right? reducing context and we're delegating context, right? You can see our planner has consumed some 7k tokens here. We're in a very small codebase. And just imagine that this is, you know, a larger task, right? 60,000 tokens, whatever. You can be guaranteed that the tokens used to plan, not all of that is critical for the building. And this makes sense. When you're engineering, when you're writing plans, you always go overboard. By

always go overboard. By the end of your planning phase, you should be deleting information that isn't relevant to the work you want done. You should go overboard, then delete. Here we have the R&D framework in full swing. We're delegating across two agents to reduce context when it matters most. There are a lot of places where it matters, but when your agent is actually writing the code, when they're actually running your agentic workflows, that's when it matters the most. And this context window here that's doing all this writing, right, chewing up our expensive output tokens, it's a focused agent with

a focused agent with a focused context window, and that means it is a performant agent. All right, and just to detail that prompt a little bit more, if we run up a little bit, here's what this agent is planning, just to give a little bit of more additional context here, right? Quite simple, so quick plan, and then here's the prompt that we're actually executing. Read TypeScript SDK, create reusable, three file wrapper system for calling agents via Claude Code, TypeScript SDK. Here are some methods, types file, low level, CLI file, create this in this directory. All

in this directory. All right, so just a simple kind of high mid-level prompt and our builder has finished implementing. We can just open up this directory and we can see exactly what was created. There's our hello calls and then inside of this directory, you can see here we have a full on application built out. We can of course, TD apps, CC, bun run tab. There's everything our bun ecosystem is giving us. we can just run, run dev, looks like a media prompt, hello, enter, and now the Cloud Code SDK via TypeScript is running. There's the response session ID, fantastic,

response session ID, fantastic, there we go. So simple prompt, simple planner, builder workflow, architect, editor, delegating across two context windows. Let's take our builder and let's run a very well-meaning feature inside of Cloud Code. A very powerful, useful feature slash compact. Okay, so you've probably used this one, but there's a huge problem with this command. After compact runs, do you know exactly what's in your context window every single time? Now, the answer

time? Now, the answer to this is of course, no. You don't know, I don't know. We have to hit Control R and reread through what this compact ended up doing. When you get to advanced agent decoding, it's time to stop guessing and start knowing. I avoid compact and I recommend that you reset and prime. You know, we can hit Control R here. We can see a decent summary here, right? Some nine step summary. You can imagine the Claude Code engineers have some type of prompt that generates a step-by-step workflow. You can see it is summarizing.

see it is summarizing. decently here. Usually it has some type of read file command where it automatically read some additional files, right? You know, you can understand why they did this. The context window is limited. They're facing the same limitations as you and I, and they want to provide solutions for them. But just like your prompts, the context window of your agents should not be handed off to any tool or team. The compact command for what it's worth is great, but it's a bandaid fix for the true problem. The context window has grown large and cannot fit any additional

cannot fit any additional information. Instead of compacting, instead of running slash compact, I recommend you run slash clear. Blow away the context window completely. Now if we run slash context, we are running a fresh focused agent. Now reset with slash prime, right? Run whatever prime command you're running and refocus on your task at hand, right? Build back up to where you were and continue forward. I know this one doesn't sound great. It's like the first advanced

like the first advanced technique, basically just saying do more work. Don't depend on the slash compact command. Why do we do this? It's because this way you know exactly what's in your context window and you get in the habit of building tasks specific context priming prompts, all right? Just like our beginner techniques adjust. These techniques stack up on each other very, very quickly. The big idea here is you don't wanna delegate the control of your context window, all right? This is a dangerous game to play. You want to own this just like you wanna control your prompt or your

your prompt or your model, the context window is the same. This is also important for Outloop agent decoding, right? It prepares you for Outloop agent decoding. And for this to work at high levels across hundreds of agent executions, you need specialized agents you know what the context will be if a compact command runs you can't know this with high confidence for outloop agent decoding no single agent should overflow their 200k tokens and trigger a compact if it does you should chop up the task you shouldn't need slash

you shouldn't need slash compact and if you need to you should reset and prime now we can push this idea a little bit further and try to do what the compact window command is doing ourselves with our next advanced context engineering technique. Notice that with each technique from beginner to intermediate to advanced and soon agentic, we're doing R and D, reduce and delegate. We're keeping track of our context window at all times and we're not outsourcing it. If you wanna scale your agents, monitoring

scale your agents, monitoring and managing the state of your context window is critical for your success, all right? Just like context priming, you can push in loop active context management even further with context bundles. Okay. So with Cloud Code hooks, you can hook into a couple of tool calls to create a trail of work that you can use to reprime your agents for the next run, right? So you can chain together agents after the context window has exploded. So the great part here is we've been using context

we've been using context bundles the entire time. So let's collapse everything and open up agents and so agents is becoming a additional agentic layer directory where you can just put output from operations of your agents. You can see we have background and we have context bundles. Let's click into bundles and let's see what we have in this directory. All right, so if we click this bundle, we have something super simple. We have slash prime and we have read. If we click into this context bundle, you can see we have our quick plan. So this was the work that happened

the work that happened inside of our planner. It read the file as specified and then it wrote this plan here for us, right? And we have the tool input and we have a couple of other things, right? This is powerful. This is a context bundle. What we have here is a simple append only log of the work that our Claude Code instances are doing. These are unique based on the day and the hour and the session ID, okay? So how does this work exactly? Fire up a YOLO dangerous mode instance and we just type prime, right? Let's just rerun a prime and let's prime our Claude Code,

prime our Claude Code, right? So we're running our prime command around Claude Code and you can see this context bundle was generated, okay? So there's the prompt and let's just pay attention to what this does, all right? We have read commands, we have search commands. Our read commands are all getting appended piece by piece and what this does is it gives us a solid understanding of 60, 70, percent of what our previous agents have done okay and so why is this important this is important because it tells a fuller story for subsequent agents to execute there's a bunch of additional read commands and

additional read commands and we're getting a log right we're getting a full-on context bundle of our agents context window Okay, this is a very simple yet powerful idea you can use to remount instances to get them into the exact same state after their context window has exploded. It also gives us a story because we have the prompt operation in here about what the context is and why the context is that way based on our user prompt. Okay, so we have this now, great, who

this now, great, who cares? Let's open up a new Claude Code instance. And let's say that this, you know, this agent's context window exploded. We can, with this context bundle, run slash load bundle, copy the path, paste it, hit enter. This agent is now going to get the full story of the previous agent. It's gonna deduplicate any read commands. And then it's going to create an understanding of the work done up till this point. Okay, and so imagine this is much larger, right? Let's say that it's something like, you know, 50 plus lines of reads

plus lines of reads and writes. We can use a context bundle to get a much more accurate replay of what the previous agent was trying to do. You can see here in the summary message, very concisely, the previous agent executed this command and loaded key findings. That's it, nine files. You can imagine this getting a lot more complicated with reads, writes, and additional prompts, but with this simple pattern, with this session ID, getting tracked here inside of this context bundle. We're saving a concise execution log, thanks to Claude Code Hooks that we can reference in

we can reference in subsequent agents. And the great part here is of course you can conditionally use this. A lot of the times you won't need to reload the entire context bundle because it won't be relevant. But if we needed to, we could get the entire replay of the agent up to the point in which the context overloaded without all of the rights and without all the details of all the reads. The trimmed down version is super important, right? We're not recording every operation. If we do that, we'll just end up overflowing the next agent's

overflowing the next agent's context window. Okay. So you do have to use this selectively, but this gets us 70% of where the previous agent was. It gets us mounted and restarted very quickly. This is another advanced contact engineering technique you can use. Check out this code base for the details on how exactly this works. Our last advanced technique is simple. It's a simple idea, it's a beautiful idea, continues to build on the techniques we've worked up to use one agent for one purpose. Maybe you've picked up on

you've picked up on this with some of the repeat themes that we're getting into, but there's no better way to control and manage your context window than to ship one thing at a time. A focus agent is a performant agent. This advanced technique forces you to sit down and answer the question, what does the pipeline of agents look like for this work? Okay. Once you start doing this well, and you understand the idea of using one agent for one purpose, if you've taken tack lesson six, you know the full version of

the full version of this, but once you start doing this well, you'll start engineering and problem solving in this two-step workflow. First, you plan out the work you want done without regard for technology. Okay. You'll focus on just solving the problem for your users, for your customers, right? Always remember, Your users and customers come first. The technology we use is a means to this end. Then you'll plan out how you'll delegate your work across several agents, forming an agentic pipeline, also known as an AI developer workflow, the

AI developer workflow, the highest level of agentic coding leverage as discussed in TAC. We'll move on from this big idea since it's the key idea in TAC Lesson 6, but this is a massive way to manage your context windows. This idea takes agent delegation to its natural, most valuable limit. Use one agent for one purpose so that your context windows are focused. A focused agent is a performant agent.

Now we've reached the agentic level. Here you've mastered all the previous levels of context engineering. This is where things get powerful and dangerous if you don't know what you're doing because your patterns will start to scale into the agentic workflows, into the ADWs, into the pipelines that you built. Okay. So let's focus on the system prompt. You can massively control Claude Code's behavior and really any agent's behavior. This can completely change how the tool works even

the tool works even more than Output Styles because we can control and start to overwrite the default Claude Code behavior. I'll say it point blank, many engineers will not get to this level. Many engineers don't need this level, okay? But if you're pushing to the edge, the system prompt gives you even more control over your agent and therefore the context flowing in and out of your agent. If you start down the path of agentic engineering, at some point, you will need to crack open and modify the system prompt. This is how

prompt. This is how you build your agents and gain find tune control over your agents and therefore your context window. There are two flags in the Cloud Code CLI and the SDK. And I'll write the full prompt out here, right? So I usually run CLDYS, right? Cloud, dangerous, Let's go ahead and just paste this in here. Then we'll run append system prompt. And then we'll pass in our specific system prompt. When you start modifying the system prompt, you can't run this in the loop, okay? So you can't open up an instance, at least not at

at least not at the time of filming, okay? You have to run this in print mode, in programmatic mode. This is where we start pushing out the loop. So we do need this dash dash print or just dash P flag. And then we run a prompt. So I'll say, what is Claude.large.md for and so that was the large you know context file that we demoed in the beginning 18 000 tokens massive then i'm going to paste in this system prompt and so check this out important when using the read tool always read in increments of

read in increments of 100 lines for example and then i give an example being really detailed with how to call this tool exactly and then if you read enough to accomplish the request a task stop reading and proceed with the task if you need more information read another hundred lines and determine if that's enough. And then we have one more instruction, important, we're tapping into an information tense keyword. When you respond to the user with your final message, always prefix your last message with check or X for success or failure, all right? And so this agent has been modified,

agent has been modified, right? We have modified the system prompt, we are controlling this agent at a lower, more foundational level. Okay. The system prompt really lets you start controlling how your agent behaves and when you control the behavior, you control the context window. So let's make sure I end the quote here and let's fire this off. You can see here, we have a concise response demonstrates what not to do with project documentation intentionally bloated using anti-pattern of over contextualization, cramming excessive details, blah, blah, blah. Okay. So it understood it ran.

it understood it ran. The interesting part here is how it ran. If we open up our context bundle and we go to this context bundle that just ran you can see something really powerful Okay, what is this file for? You can see our prompt and you can see the subsequent reads. Read 100, read 100. This agent is obeying the specific instructions in our system prompt. We're saying read 100 lines at a time. If you have enough information, stop executing and respond, right? Proceed with the task. This is super, super powerful. We've

super, super powerful. We've just reduced the number of lines our agent had to read with the read tool, okay? And we forced Cloud Code to increment. This is super powerful. And this is just one simple way, one simple control mechanism for steering this agent in a completely different direction. You can push this even further using the Cloud Code SDK. In addition to the append system prompt command, there is also a SDK specific custom system prompt variable that you can pass

that you can pass into the SDK. Do not use that unless you know what you're doing. The Claude Code team has put a ton of work into crafting the system prompt be a top tier agent for engineering. If you use, I think it's called a custom system prompt, I'll of course link all the documentation below in your loot box. But if you use this variable, you will blow away the system prompt, use this with caution. Okay. And so we can run another one. So we have another prompt here, same deal. We're reading in chunks of 100. Figure out what

100. Figure out what Claude Code hooks are available and their respective input schemas from the documentation. Okay. So I'm gonna fire this off. Here's that context bundle running and you can see that same deal. There's all the response formats for every hook based on the existing documentation and there's the available hooks. But you can see here again in the context bundle, we're saving the actual read executions and the tool input. We've overwritten the calling mechanism for reading files. You can see there that same pattern, reading 100 at a time of the

a time of the Claude Code Hooks directory, For this one, it needed to read more to accomplish this task, so it did. I recommend you only use this agentic level context engineering technique when nothing else works or when you start building your custom agents for your domain specific use cases and when you start deploying agents inside of your codebase. Check out the agentic horizon extended lesson on cloud code SDK mastery. There we break down the Claude Code SDK so that you can run this in a more programmatic way so you can build out specific

can build out specific agents inside of your codebases. This is where everything is going. Specific agents with specialized context windows solving your problems extraordinarily well. The focus should always be better agents or more agents? When you're adding more agents, you're pushing into the D, the delegation and the R and D framework. You're pushing it to the max. You're using one agent for one purpose. And when something goes wrong, you fix that piece of your workflow.

piece of your workflow. Now with primary multi-agent delegation, we're entering the realm of multi-agent systems. In TAC, with each lesson, we built up variants of a multi-agent pipeline using this very technique. And in lesson eight, we showcase several different multi-agent workflows and systems and uis right there are many ways to delegate work at a high level but when you get down to it if you want to create an on-the-fly primary agent you have two options you have the cli and you have sdks at the mid and high level we can kick

level we can kick off primary agents through prompts, through wrapper CLIs, through MCP servers, and through UIs. You've likely seen a lot of Claude Code management systems and a lot of agent systems get built up into their own UIs. That is primary agent delegation. Now, what's the most lightweight version of multi-agent delegation. You can use ASAP and get value out of ASAP. It's a simple reusable custom slash command. If you remember inside of the cloud directory

of the cloud directory in our commands directory, we have background.md. This is a simple single prompt that boots up a background Claude Code instance. This is the simplest, quickest way, other than going right through the CLI, to delegate work to agents. When you use a pattern like this, we're pushing in to powerful Outloop agent decoding by running a single prompt with a single agent that does one thing, reports its work, and then it finishes. So let

it finishes. So let me show you exactly what I mean. I'll run Claude Opus in Yolo mode here, and then I'll say slash background. And you can see here, this fires off a full Claude code instance in the background. Here's our argument hint, prompt model report file. I wanna kick off the creation of a plan. There's no reason for me to sit here in the loop prompting back and forth when I can kick off a background agent, when I can delegate this work outside of my primary agent's content context window, right? We're delegating this work out. I can open up some quotes here, paste this in, and

paste this in, and this is going to kick off a new quick plan. So we're running that plan workflow, that plan agentic prompt again. This time we're building out a cloud code. These are just random code examples. We're going to read a couple of pieces of documentation and this time we're building out a astral UV Claude Code, Python SDK with that same format, right? Those three files by Dantic types, low level files, CLI file, right? Specifying where to create it. This is the plan. Let's fire it off. This is going to kick off a background agent. Okay. And so

agent. Okay. And so you can see our primary agent getting to work here based on the contents of this prompt. We can of course see that, you know, consistent prompt format where you're reusing great prompt structures that get work done for us. Again, check out, the agentic prompt engineering, agentic horizon extended lesson to learn how to write great prompts for the age of agents. And it's all inside of the workflow step here, right? So create the agents background directory. We have our default values. And then this is important, we're creating a report file, okay? And

report file, okay? And then we have this primary agent delegation, XML wrapper, where we're detailing a bunch of information for our agent, okay? We are kicking off a Claude Code instance from Claude Code. We have compute orchestrating compute, agents orchestrating agents, okay? This is where everything is headed. Better agents and then more agents. Once you master a single context window, you can scale it up. There's a format here, blah, blah, blah, skip to the bottom. But the important thing here is that this free up the primary cloud code instance. You can see we have a background task, background cloud

background task, background cloud code kicked off. If we open this up, this is the file that our agent is going to be reporting to. And so cool thing here, we can open up a context bundle for this agent, right? So if we hit up here, you can see that exact prompt background slash quick plan, read, blah, blah, blah, blah, blah. This agent is starting to work, all right? It's starting to create this plan. And we can see that with the context bundle. You can see this is super useful adding logging, having these trails, there's the actual plan just got written there. Having this trail, this story of

trail, this story of what your agents have done is an important agentic pattern. We are building up on every context engineering technique we've used thus far. This agent should report back to its report file here. This is a great way to track the progress of your agents as they work in the background. So you can see here, we still have that one background task running. We should get an update here. Our agent has, there we go. So you can see it's reading its background file now. And then soon it's gonna put the right in here. We should see this come in live as our background. delegated agent

our background. delegated agent instance is just writing this plan for us. There's no reason for me to sit in the loop. I know exactly what this does. And here is the output. Check this out, progress task completed. It renamed this file. I have an instruction to rename the file when it finishes, 1302.53. We can click this. It is now complete. A very quick one prompt agent delegation system It's all here for you in this codebase. Think of these as starting points for understanding

starting points for understanding what you can do to better manage the context of your agents. It's all about the patterns. It's all about taking control of your agents context windows and scaling it to the moon. The more compute you can control, the more compute you can orchestrate, right? The more agents you can orchestrate, the more intelligence that you can orchestrate, the more you will be able to do the limits on what an engineer can do right now is absolutely unknown. Anyone being pessimistic, ignore them. Don't take my

them. Don't take my word for this. Ignore me as well, but investigate the optimist in the space. See what they can really do. See what we're really doing here. We have background, compute, agents calling agents. We have the R&D framework, 12 context engineering techniques. These are concrete things. Maybe a couple of these techniques fly over your head or you're not interested or you think it doesn't apply to you. That's fine. Just take one. a couple of these and improve your context engineering. The background agent task and multi-agent

agent task and multi-agent delegation is super important because it gets you out the loop. This is a big idea we discuss in TAC and it extends into context engineering. Get out the loop, set up many focused agents that do one thing extraordinarily well. In a lot of ways, multi-agent delegation is just like sub-agents, but we get complete control. We're firing off top-level primary agents from our in-loop primary agent here. Okay, so there's

here. Okay, so there's a lot more control here. This background agent and the prompt that I passed in, right? We can just paste this prompt. I could have asked for anything here, right? This doesn't need to be a quick plan. I could have asked for a multi-agent workflow running sub-agents, right? There's just so many ways to build and to use multi-agent systems. The key idea here is, let's bring it all back to context engineering. The key idea here is you can delegate specialized work and focus agents by

and focus agents by building out some type of primary agent delegation workflow you can see here in just one prompt we have a full Claude Code instance in the background doing work for us that we know we don't need to monitor anymore and the more you become comfortable and the more your agentic engineering skill improves the more you can stop babysitting every single agent instance okay this is a big theme in tech we want to scale from in loop to Outloop to ZTE. Speaking

Outloop to ZTE. Speaking of specialization, speaking of all these big ideas, let's wrap up with potentially one of the most powerful context engineering techniques. Let's talk about agent experts. So what does this all build up to? We've already, covered the main idea, right? Build focused agents, deploy them in ADWs with specialized pipelines, protect your context window at all costs inside of every agent. But once you put all this together, you can get something really special, something

something really special, something really powerful. There's not really a name for this yet, but I've been just blatantly calling this pattern agent experts. The idea is simple and powerful, especially for context engineering with agents on large codebases. Okay, this idea is echoed inside of TAC with templates. You can use your agent delegation of choice. You can use your primary agent, primary delegated agent, or sub-agent. And the whole idea is that you fire off specialized agents that are experts at specific parts of your codebase. And here's

codebase. And here's the kicker, you have them auto update their own knowledge. This is the agent experts technique. Let me show you exactly how. Inside of our Claude commands directory here, we have an experts directory. Right now we have a single expert in this code base and you can see this agent expert is focused on Claude code hooks. Now, before we move forward, let me just kick off this expert. So I'm gonna run this prompt and I'll just paste this in for brevity. I'll type slash experts. And so now we can just see all of our experts and

of our experts and I want our planning Claude code hook expert. And now we'll paste in a prompt. Okay, so I'm gonna paste this in. This is a simple high to mid-level prompt, We want our expert to take the wheel on this, all right? So what does this do? Long story short here is, you can pause the video and read it if you want. We're gonna create a output structure. So we have agents, hook logs for every Claude Code instance. We want a full log of every event so we can improve our agentic coding, right? We want additional monitoring. So how are we gonna do that? We're gonna have our Cloud

gonna have our Cloud Code hook expert build this directory structure. Agents, hook logs, session ID, name of hook, okay? Let's fire this off and let's understand what our expert can do. All right, so let's open up this prompt. We want the Cloud Code Hook Expert plan. This is gonna look very similar with an additional section that you probably haven't seen before. We have an expertise section. Now, this section on its own, it's not that useful. It's not that different really than our instructions or our workflow. But the

our workflow. But the key here is we have a three-step agent expert. Let's open this file explorer up again and you can see here we have plan, build, improve and it runs in that flow. Okay, so this agent right now is planning for us. It's a specialized Claude Code hook planner agent. So it's built just for planning Claude Code hook related functionality. We'll then pass it off to our expert builder, which is gonna take the path to the spec that our planner created, and the agent that runs

the agent that runs this prompt, as you can imagine, is gonna be specialized to running Claude Code hooks, right? You can even see directory structure all the relevant files to this specific piece of our codebase right you can see here we're building experts we're not building random one-off agents random agent instances we've built a reasonable prompt that mounts and you know to echo all the way back to our beginner techniques we are in a way priming this agent to be an expert at this area of focus

this area of focus okay a lot of the work i do is aimed at showing you the vision and giving you the new beliefs and the new ideas, the new context that you need to deploy agents, to deploy generative AI in new forward leaning ways. Okay, so this is just one idea, but you can imagine multiple experts across your codebase that are extraordinary. They're like the engineer on your team that knows that one piece of code, that one feature better than anyone. Now you can encode this, you can template it

you can template it into an expert, agent expert and here's the cherry on top after you implement the plan after you have your expert build it right specialize at building this specific type of work you can run your meta improvement expert okay you're a Claude Code hook expert specialize in continuous improvement you'll analyze the work done blah blah blah and update your plan and build experts so we have a prompt built improve our prompts. Okay, we're

our prompts. Okay, we're very close to the edge here. And you can see where this goes for you, right? It's auto documenting itself improving. Let's go ahead and continue this workflow. You can see here our spec got created, you know, we have a great spec here detailing exactly how this works. Feel free to pause at any point. And I'll go ahead and just commit this work with the elite context engineering codebase so that this feature will be built out will be logging this structure by the time you get your hands on this. All right, I'm going to copy the reference to this, I'm going to a Of course, I'm not gonna use this existing context window if we

context window if we type slash context. Already spent 26K, even though we could chain on top of this agent, we are not. We are practicing, we're preparing for Outloop agents. We're thinking about this as if we're building a pipeline of agents. I'm gonna open a new instance here, Claude, Yolo mode, Opus, and then I'm gonna type slash expert. We're going to build this feature and then we're gonna paste in the path and let this fresh focused agent cook, okay? We have one agent planning,

have one agent planning, we have the other building, and we have the last self improving. Whatever changes we make to this system, our improve expert, our sub prompt, our sub agent inside of this three step expert is going to look back at the changes made and update the plan and the build to have the details of the implementation. The planner thinks about what needs to be done and then its context window is gone, right? We don't need it anymore. The builder takes the plan and actually implements it, right? This is a

right? This is a classic pattern. Big shout out to the legacy AI coding tools, the old school tools, Ader, and all the other tools that separated planning and building. This is a pattern that is going to continue across. And as you saw in TAC, this pattern can continue and expand across the software developer lifecycle. Here's our new hook logger getting built out, CHMOD. It has everything it needs you deploy this into single file scripts, right? It has the information, it is an expert. I've built an expert set

built an expert set of agent prompts into the codebase, okay? This is what it looks like to continuously build and improve on the agentic layer of your codebase. You're going to end up with experts, okay? Agent experts that can remember and build and improve on areas of your codebase that you will not remember anymore, okay? you know, even the best engineers, you know, we just lose track of this stuff over time, all right? That's natural. But now we have agent experts. And yes, this is

And yes, this is another, you know, investment you have to make into your codebase, you have to maintain your agent experts, but this is going to be, it looks like our hooks are coming in now. Let's go ahead and look at agents hook log. And you can see there, there's a couple of test runs coming in. It looks like this agent is starting to validate their own work with a closed loop prompt. You can just start to see this stuff stack up very quickly. Okay, so this has been elite context engineering, all right? This is where it all goes. Once you master

goes. Once you master the context window of a single agent, you can make your agent do more because it has more space, it's focused, and then you can scale up how many agents you can control and steer at any one point in time. So now we have this implemented. Let's see, you always wanna review the work. At a high level, I can just quickly come in here and see that looks great, universal logger. Okay, looks great. It is adhering properly. It is aligned. Now if we open up a new instance here and kick off Claude, you can see we have this feature built

have this feature built out exactly as specified. Okay, so there's the start session JSONL. We can type hi, we're gonna get whatever the user prompts submit, and then we're gonna get some flows coming in. ahead and run, right? We got a stop command. Let's go ahead and run prime. This is going to run a series of operations, right? Let's go ahead and kick that off. And then you're going to see the logs come in. That was built perfectly in one shot with a planner and a builder as an expert, right? These are agent experts. Let's run the final step and let's talk about the future of context engineering. Okay. So we're

engineering. Okay. So we're going to run this new Claude Code instance in YOLO mode. You can see that log got appended there. Our agents, right? In our system, our agentic system is keeping track of all types things now log hooks context bundles we can fire off background agents if we want um but all we want to do now is expert improve okay no params We just improve and it does this by looking at the git diff. It looks at any changes and then it makes the improvement to our existing build and

our existing build and plan Claude Code hook expert in our code base. Okay, so you're gonna see these changes here flow in. You can see our expert is preparing, it's priming itself to improve what's been done. It's gonna run a git status in a second here and see any relevant changes that are relevant specifically for the files it has detailed and you can check out the prompts of course in this codebase, classic, great agentic prompt engineering in all of our prompts here. But you can see it's doing this work and it's going to self improve. There we go.

improve. There we go. I've identified several changes relevant learnings, relevant changes from the universal log implementation. That looks great. If your codebase is large or you have a highly technical area that requires your expertise or another engineers on your team, you know, I highly recommend using the agent experts pattern. Of course, you'll have to maintain and monitor your expert, but this is much better than having it stuck in your head or an engineer's head, right? You want your agentic layer operating your code base and you operate the agentic layer, right?

the agentic layer, right? You know this. If you've taken TAC, we build the system that builds the system. Our improving meta agent expert is now updating based on the Git status, right? Based on the Git, you know, Git execution run. It's updating our build and plan. And here's the summary of what was changed, right? It just added a couple sections to the expertise section. So we have a dedicated section inside of both our plan and our build dedicated to specific expertise that gets updated on the fly. It's

on the fly. It's dedicated, it's differentiated. We don't want this to be in the workflow or in the purpose or in the instructions. We have a dedicated section built for this. We're following great agentic prompt engineering. We're not conflating our headers. We're not conflating our sections. It's very important. And this pattern, the agent experts, It brings us right back to the highest leverage point of agent decoding, the ADW, the AI developer workflow. You can imagine a workflow in ADW where we string together these

we string together these three prompts in three individual agents. plan, build, pass the plan to the build, and then improve, and then we run our git commits after, right? This is an entire workflow. All we do is pass in some prompt, a high-level prompt that we want, and then this workflow, this specialized agent takes it from there, okay? There are many directions to go with this. You can imagine a router agent that takes in any high-level prompt and then determines what expert to run. There are many ways

There are many ways and directions to take this, but I wanna leave that up to you, take these 12 techniques and apply them, get value out of these techniques. All right, yes, it takes some time. Yes, you have to invest. This is not vibe coding, okay? If it's easy, a vibe coder is probably doing it and that isn't irreplaceable, okay? That is replaceable work. Even one of these can save you massive time, but you have 12 here. Pick one, pick a couple, dive into them, deploy it into your agentic coding to improve your context engineering.

Managing your context window is the name of the game for effective agentic coding. And remember, it's not necessarily about saving tokens. It's about spending them properly. We manage our context window so that we don't waste time and tokens correcting our agents' mistakes. We want one-shot out-loop agent decoding in a massive streak with the fewest attempts and large sizes so we can drop our presence. In TAC, we use specialized agents, we delegated and we reduced the context

we reduced the context window of our agents by building specialized ADWs that shipped on our behalf. So the big idea here is simple. It's measure and manage one of the most obviously critical leverage points of agentic coding, your agent's context window. Here are a few future context engineering trends you can bet on coming out of the big AI labs. You can imagine a larger context windows. All right, this is obvious and self-explanatory. We want more context to get around the compact problem. Right next

compact problem. Right next to that and very, very closely related, we are likely to see better context windows coming out of these big labs. Language models, they tend to lose massive capability as the context size grows. This is an attention mechanism problem inside of modern agents. You can plan and bet on big labs focusing on better effective context windows. Okay, another big idea Here is hot swapped context windows, hot swapping tools, hot swapping context in general, right? Hot swapping the system prompt like cloud codes, output styles enable

codes, output styles enable us to do, right? You can overwrite and therefore hot swapping existing system prompt. This is an important, interesting pattern. Imagine for every piece of context, user prompts, assistant prompts, tool calls, system. You can swap in and out different contexts, right? You can delete context to free up the context window, okay? Hot swapping context is a big idea we're likely gonna see, okay? The last two are very obvious. You can see these if you're on the edge, you're already doing this and you're using TAC to help you get there faster, quicker, better.

there faster, quicker, better. Multi-agent architectures for agent delegation. Okay, we touched on this several times throughout TAC and here we use sub-agents and primary agent delegation. Okay, and then lastly, a big trend you can bet on, specialized agents everywhere. On the bleeding edge, you plug into the Claude Code SDK and other agent SDKs and you specialize every element of the context, the model, the prompt, the tools solve and deliver unique experiences for your users and for your customers. Okay. What's better than a prompt? A prompt chain. What's

A prompt chain. What's better than a prompt chain? An agent. What's better than an agent? Many focused, specialized agents that deliver value for you, for your team, and most importantly, for your customers and users. Don't miss this trend. You now have everything you need to win and ship with focused, single-purposed agents. So all these techniques are us battling with the fact that there are key scaling laws and algorithms inside of these language models, inside of generative AI that decreases performance

AI that decreases performance as context window grows. What does that mean? It means you can safely bet on spending your engineering time, energy, and resources on investing in great context management, in great context engineering. It's a safe bet to bet on context engineering. With all the focus on context, let's not forget about prompt engineering and specifically agentic prompt engineering. If you're writing bad prompts, your context doesn't matter. If you can't communicate what you want done with

you want done with your agents when you're delegating when you're reducing context, you're going to be massively limited and you're going to be shooting yourself in the foot, wasting money, right? If you want to write the best prompts and preserve your context window, you want to be stacking up these big ideas. You'll get a ton of value out of the agentic prompt engineering extended lesson I've built out for this very purpose. That agentic horizon lesson is dedicated purely to agentic prompt engineering in the age of agents. We'll be optimizing prompts for

be optimizing prompts for Claude Code, but really all agent decoding tools. We're betting on the winner and we're preparing for competitors. And of course, if you wanna build specialized agents, check out the Claude Code SDK Mastery. You wanna be using the Cloud Code SDK and agent SDKs to solve your domain specific problem better than any chat interface or any prompt or any generic Claude Code instance can, all right? So check out Cloud Code Mastery extended lesson to build your own custom agents. Fantastic work

custom agents. Fantastic work here. There is a lot to digest. This lesson is going to be here for you. Thank you for trusting me. Keep in mind, a focused agent is a performant agent. I'll see you in TAC and I'll see you in the next Agentic Horizon lesson.