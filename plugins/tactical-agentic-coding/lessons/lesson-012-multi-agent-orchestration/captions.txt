Engineers, Welcome to Agentic
Horizon, Lesson 4. This
lesson is going to
change the way you
think about agents. If
you like the way
things are, close this
tab now. If you're
ready for the next
step, throw on your
headphones, cancel out the
noise, and let's focus.
I'm very excited to
be here with you
be here with you
right now. We live
in an incredible time
of extraordinary opportunity. Our
potential as engineers has
never been higher. With
the abundance of opportunity,
there's a ton of
noise, confusion, and the
fear of change and
instability is always present.
Let's silence the fear
once again by pushing
what we can do
forward and by understanding
the next opportunity available
to us. There is
one mode of engineering
one mode of engineering
that matters above all
now, agentic engineering. Here,
we don't focus on
the application layer, we
focus on the agentic
layer. We build the
system that builds the
system. If you're watching
this, you've been scaling
up your agentic engineering.
You've got better agents,
you're running more agents,
and maybe you've built
custom agents specialized for
your domain-specific problems. But
if you haven't yet,
you will hit a
you will hit a
wall. There are hard
limits on the current
interface of agents. You
can't scale by hopping
into one terminal at
a time, writing one
prompt at a time.
As a tactical agentic
coding member, you know
the solution to this.
Build a layer of
agents around your code
base with repeatable workflows
using AI developer workflows
and leverage points of
agentic coding. But as
powerful as this is,
there's an upfront investment
we need to all
pay down to build
pay down to build
this layer. So what
if we had an
intermediate step, a system
of agents that helps
us build before we
have an agentic layer
and while we have
an agentic layer? Because
at scale, if you
lose track of your
agents, you lose control
of your results in
the generative AI age,
the rate at which
you can create and
command your agents becomes
the constraint of your
engineering output. When your
agents are slow, you're
slow. When your agents
have a problem, you
have a problem, you
have a problem. If
you're using agents at
scale, you know exactly
what I mean. Right
now, every engineer sits
at one of these
levels. Base agents, better
agents, more agents, and
custom agents. The theme
here is simple. At
each step, you scale
your compute to scale
your impact. When you
combine this with your
agentic coding KPIs, you
understand where you are
on the agentic engineering
proficiency curve. It's not
about what you can
about what you can
do anymore it's about
where you can teach
your agents to do
for you there's one
more level one giant
leap forward I'm going
to share with you
in this lesson Engineers
like you and I
using agents every single
day, we're all thinking
about the same thing
and the votes for
agentic horizon show it.
In order to scale
your agents, you need
to manage your fleets
of agents. Multi-agent orchestration
is the next step
is the next step
in our journey as
agentic engineers. So let
me introduce you to
one powerful multi-agent orchestration
solution. The one agent
rule them all. The
Orchestrator Agent. This is
the single interface pattern
applied to your fleet
of agents. It's an
existing engineering paradigm that
great engineers have used
for decades. We're applying
the single interface pattern
to agents. But it's
not just the Orchestrator
Agent that matters. We're
Agent that matters. We're
combining three pillars. The
Orchestrator Agent, your unified
interface to your agents.
Your Orchestrator Agent unlocks
CRUD for your agents.
This gives you agents
at scale. And lastly,
we're combining observability for
real-time monitoring of your
agent's performance costs, and
as you'll see, results.
When you combine these
three, you get a
powerful solution to multi-agent
orchestration. This is you
controlling your compute at
controlling your compute at
scale. Welcome to Agenta
Horizon Lesson 4. Let's
understand the one agent
to rule them all,
the OA. Where is
our input field? This
is not a normal
application for normal users.
This is for you
and I, the agentic
engineer. We're maximizing information
density without losing UX
quality. If we have
command K here, we'll
see our prompt input
interface. It has useful
interface. It has useful
metadata about the capabilities
of this codebase
we'll cover in a
moment. We'll just start
with a simple ping
prompt. Our orchestrator agent
is going to of
course give us a
quick response. Now let's
spin up some agents.
Here we're gonna create
three individual agents. We're
gonna have them summarize
the codebase, build
an application structure summary
inside of a markdown
file with mermaid tables.
We're gonna fire this
off and truly show
off the potential and
the capability of an
the capability of an
orchestrator agent. Now our
orchestrator agent is going
to craft three new
agents, and then prompt
them. So we're going
to have a total
of six unique tool
calls built around managing
and orchestrating agents. You
can see here, here's
our first agent, here's
our second agent, and
our orchestrator agent is
gonna spin up our
third agent right now,
our QA agent that's
gonna do both the
front end and the
back end summarization work.
There's our QA agent,
and you can see
right away, this is
right away, this is
a differentiated agentic coding
experience with multi-agent observability,
you can see everything.
Observability is a key
component of a successful
multi-agent system. Why is
that? It's because if
you can't measure it,
you can't improve it.
And if you can't
measure it, you can't
scale it, okay? If
you have 10 agents
doing the wrong thing,
does it matter that
you have 10? Of
course not. This is
why observability is key
and it's also why
the orchestrator is an
the orchestrator is an
advanced agent decoding concept.
It comes last after
custom agents. You can
see here we have
an interface that is
communicating the work of
every one of our
agents. So we have
responses, we have tools,
we have thinking. We
can, of course, filter
on any one of
these. We can filter
on responses, individual tool
calls. We can filter
on our individual agents.
So here's just our
QA agent. The observability
here is essential for
scaling impact. with a
single prompt, I've deployed
single prompt, I've deployed
three times the compute
an engineer working in
the terminal has, okay?
And this is just
the beginning. We have
two fast agents. We've
divided this work into
front end, back end,
and then we have
a primary kind of
powerful agent that's going
to do the QA
work of summarizing both
the front end and
back end. And our
orchestrator took care of
actually commanding and creating
our agents. If we
scroll back up, you
can see all six
of those tool calls,
create agent, create agent,
create agent, and then
create agent, and then
three command calls. Already,
we have this very
interesting pattern of our
orchestrator agent taking our
high-level prompt and then
writing out in much
more detail the actual
concrete work that we
want done to our
agents. Already, this is
a differentiated experience. I
know right away some
engineers are gonna think,
aren't these just sub-agents?
Why aren't you just
using sub-agents? Having a
primary agent here connected
to your orchestrator agent
is differentiated. You're gonna
is differentiated. You're gonna
see this over and
over and over. We
can do a lot
more when we control
our agentic units with
our orchestrator agent. So
some of our fast
agents here running Haiku,
they're of course going
to get work done
quite a bit faster
and when they complete
their work, you're going
to see something very,
very powerful. And you'll
notice throughout all of
this, our orchestrator agent
has stopped doing work,
right? Its orchestration tasks
for the meantime is
completed. It has created
completed. It has created
and commanded our agents.
Now our agents are
doing the work. And
if we dial into
the individual agent user
interface here, you can
see a couple of
key, key things. We
have the name, we
have the status, we
have of course the
context windows. We're managing
the core four of
every single agent we
spin up. If you
do not adopt your
agent's perspective, if you
do not know what
they can do, you
do not know what
you can do. We
have our response messages,
we have tool calls
and we have hooks.
And of course we
have reasoning. You can
have reasoning. You can
see here, none of
our agents here are
thinking they're not reasoning
at all. That's okay
for these tasks. We
of course have our
models and our costs.
Now, something incredible just
happened. As you can
see here, our primary
QA agent has finished
its work. We have
its consumed assets, and
it's produced assets. Engineering
is all about communicating
work. So your multi-agent
system should reflect that.
It should showcase that.
And so right here
And so right here
in a single response
message, you can see
the actual read files
and the produced files
from our QA agent
at a glance. We
can do something really
powerful. We can of
course just see the
diff right here in
line, but more importantly,
we can one click
into our editor. So
now we're operating inside
the loop. We're looking
at this file. We're
actually reviewing and understanding
what's been done in
markdown mode here. We
can see exactly what
our agent has broken
down for us. And
this is a great
opportunity to actually talk
opportunity to actually talk
about the codebase
architecture. And to be
completely clear here, our
multi-agent application here, our
agents, our Oracle Shure
agent, this codebase
is pointed back at
itself. Okay, so the
working directory is the
multi-agent orchestration system, right?
We are using the
system to build the
system quite literally. Let's
go ahead and understand
what this is and
how this looks, okay?
So you can see
here, four key components.
And we asked for
concrete mermaid diagrams. We
concrete mermaid diagrams. We
have our front end
layer of a pina
store, We have our
services, all right? So
we're running HTTP and
we're running WebSocket. So
we're using both of
these to connect to
our backend. In our
orchestrator service, we are
of course using the
Claude Agent SDK. Claude
code is the best
agentic coding tool. It's
not just the agent
or the agent harness
that makes this tool
great. It is the
extensibility of this tool.
We can build up
powerful multi-agent orchestration systems
like this, thanks to
how pluggable the Cloud
how pluggable the Cloud
Code ecosystem is. So
we have our AI
pieces here. The most
important thing here is
that we have separated
our orchestrator agent from
our command level agents.
All right, we also
have, this is super
important as well, we
have a data layer.
Everything we're doing here
is operating and firing
into a Postgres database
with concrete structure. Why
is that? Why haven't
made that architectural decision?
It's because this system
is in fact an
Outloop Peter system. We
Outloop Peter system. We
are observing work from
our agents outside the
loop we are quickly
operating, right? You saw
that. This is quite
literally a prompt input.
We then have our
trigger, which is our
HTTP requests coming into
our server. And then
we have our full
on environment. In this
case, it's just running
right on my local
environment. And of course,
we have multi-agent observability
to manage the result
of our Peter framework.
Remember tactic four, stay
out the loop. You
should be compounding your
engineering with each leverage
engineering with each leverage
point of agenda coding
that you add to
your codebase and
then you build a
system or you find
one that lets you
solve problems as you
continue to move from
in loop to out
loop. There are so
many problems that you
do not need to
be sitting in the
terminal prompting back and
forth to solve. All
right, keep in mind
a specialized tool like
this is going to
be more powerful than
some out of the
box cloud-based tool. Why
is that? It's because
these tools are designed
for everyone's codebase,
not yours. When you
not yours. When you
build something like this,
you get specialization all
the way down. It's
super important to note,
I have this deployed
for several codebases
I can access anywhere,
anytime, through multiple devices.
And it's all because
it's designed as an
Outloop system. This is
a critical component of
the system to mention,
all right? So we
have a bunch of
additional documentation here. You
can see this agent
did a really great
job of summarizing everything
going on. There's the
table structure, and this
is all gonna be
is all gonna be
here for you to
check out once you
finish this video. I'm
gonna go ahead and
clean up some of
this documentation. And if
we hop back to
our agentic system, you
can see our front
end and back end
agents have also completed
their work. We can
see all the files
they've consumed, we can
see the actual concrete
produced results. Okay. You're
not getting this with
out of the box
agent decoding tools. You're
not getting this with
any cloud tool, right?
This is a specialized
solution for managing agents
at scale. This is
multi-agent orchestration. So we
multi-agent orchestration. So we
can dive into any
one of these results.
You can see here
our back-end QA agent
went pretty hard here
on the back-end docs.
This is all fantastic.
We can of course
dive into any of
this if we want
to with a single
click and we'll be
taken right into the
piece of documentation that
we can then tweak,
delete, modify, and so
on and so forth.
Another massive advantage of
our orchestration system is
this. It's designed to
help us manage our
agents at scale. Okay,
agents at scale. Okay,
so we can prompt
something like this. List
agents and then check
the status of our
agents, okay? And so
this is going to
kick off our orchestrator
agent once again and
have it actually understand
the work that was
done. Now, this is
super important. Our orchestrator
agent is not always
looking at the results,
right? I mean, look
at what just happened
there between all these
agents. It's incredibly overwhelming.
There's too much information,
okay? And so what
we've done here with
our orchestrator agent is
that we've designed it
that we've designed it
to be a, this
is super important, we're
gonna touch on this
in a moment, we've
designed it to be
a custom agent special
specialized at solving the
problem of managing other
agents. And to do
that, we have, of
course, adopted our agent's
perspective. It is not
always observing the logs.
It cannot be. We
have to protect its
context window. This is
true for your O
agent. This is true
for your primary agents.
You always need to
be monitoring and understanding
the core four of
every agent you boot
every agent you boot
up. Remember, on top
of every feature, any
lab builds, any UI
that you see, any
experience, it's all just
the core four. Don't
let anyone confuse you,
okay? Context, model, prompt,
tools. Do you know
what these four leverage
points are at every
critical moment? All right,
this is key. As
you can see here
through our interface, We
have a really great
idea of the state
of the core four
for all of our
agents. Okay. And so
agents. Okay. And so
you can see here
the orchestrator agent, you
know, ran some specialized
tools to actually check
the status of every
agent. Check this out,
right? Agent name. And
we're going to expand
this a little bit
here. Agent name. tail,
agent name, tail. It
is actually looking at
the response logs here
and then it's communicating
to us, all right?
So this single interface
pattern is very important
here for orchestrating agents
at scale. We're protecting
context windows, We have
specialized, dedicated, focused agents,
specialized, dedicated, focused agents,
right, focused on one
specific task. This is
important. We're gonna touch
on that in a
moment. And then our
orchestrator agent is communicating
to us, okay? We
can continue our work.
This is the powerful
part of having a
system like this, okay?
build anything we need
to to get the
job done. So you
can see here, we
have a bunch of
metadata. We'll cover that
in just a moment.
Let's just run this.
I'll say command all
agents, create one section,
a single sentence of
each key node in
the system. Quick, concise,
enable thinking. All right,
enable thinking. All right,
so let's get thinking
mode turned on here
and we'll go ahead
and fire that off.
So once again here,
the pattern is the
same. We are talking
just to our orchestrator
and then our orchestrator
is running the multi-agent
prompts. Okay, so there
it goes, prompt one,
prompt two, prompt three,
and you can see
that key, ultra thinking
keyword in our individual
agents. We have the
brain icon here, and
now they're starting to
actually think through what's
going on here. This
should be just a
quick summary. They're gonna
make a quick change
to the top of
their file. These aren't
their file. These aren't
just one-off sub-agents where
the context is blown
away or we have
to kind of manage
what or where the
sub-agent was. These are
primary agents that we
can tap into over
and over until that
specific job is done,
okay? Something that's gonna
happen here, it's gonna
be really important. Here
are our results. Once
again, we can just
dial into these. We
can see all the
consumed files versus produced
files. This differentiation is
very important. We can
continue to run them
until the job is
done. It's important that
done. It's important that
our orchestrator agent can
tap into each agent
when it needs to
command them, read from
them. But again, we
don't want our orchestrator
agent getting involved in
the actual work. It
is just here to
orchestrate. This is our
single interface into multi-agent
orchestration. Let's look at
our front end summary.
So if we just
click into this, we
should see a front
end key nodes. So
check this out. We
have our key components.
We have our composables,
we have our services,
and we have our
core files. So this
is great, right? We
is great, right? We
got a key summary
here. You can see
all the key technologies
we used for the
front end. And this
was a great summary
written up by our
fast front end keyway
agent. So this is
fantastic. We can hop
in the loop when
we need to, when
we understand what's done,
we're back out the
loop. We are constantly
moving from in loop
to out loop and
the multi-agent orchestration with
the O agent helps
us reduce our presence,
it helps us understand
what our agents are
doing, and it helps
us scale our agents.
Now that the job
is done, whatever work
you needed your agent
to complete, it's finished,
okay? Now we can
do something very powerful.
There's a journey that
every engineer goes through.
First, you learn how
to read code, then
you create code, then
you update code, and
then in the end,
you learn that the
best code is no
code at all. You
learn to delete. Command
K, delete all agents.
Agentic engineering is no
different. You must treat
your agents as deleteable
temporary resources that serve
temporary resources that serve
a single purpose. You
can see three tool
calls came in there.
Our orchestrator agent has
blown away our agents.
The work is done,
the job is done.
Let the agents go
home. In Tactical Agent
Agentic Lesson 6, we
dial into this concept
with one key tactic,
one agent, one prompt,
one purpose. This is
something that 80% plus
of all engineers are
rediscovering over and over
every time they explode
their context window, okay?
their context window, okay?
Focusing your agent on
one task sidesteps all
of these context issues,
okay? Context rot, context
pollution, toxic context, whatever
you want to call
it. You want your
agents to be just
like you, a focus
engineer working on a
single task at a
time. Let your agents
focus, all right? And
multi-agent orchestration with our
O agent lets us
do just that. What
are we doing here?
We're tapping into the
R and D framework.
We discussed this inside
of the Elite Context
of the Elite Context
Engineering Agentic Horizon lesson.
We are reducing and
delegating context to the
max, okay? By the
way, if you haven't
completed Tactical Agentic Coding
and the previous Agentic
Corizon lessons, stop this
video, go watch those.
All of this will
make a lot more
sense. We are compounding
our engineering with tactics
of agentic coding and
powerful patterns over and
over and over. Okay,
every single lesson matters.
Every single lesson was
designed to have a
critical idea, a critical
tactic to push what
tactic to push what
you can do further.
You know, let me
be clear, I'm super
excited for larger effective
context windows, but 200K
context window is plenty.
You're just stuffing a
single agent with too
much work, just like
your boss did to
you at your last
job. Okay. Don't force
your agent to context
switch. You know what
that feels like. Force
it to focus and
then let it go
home back to the
data center. Delete it.
So very powerful stuff,
right? We're gonna clear
our logs here. Our
orchestrator agent is just
ready and waiting. It
ready and waiting. It
has no agents in
the bank, but it
can create them on
the fly when we
need them to solve
work at scale quickly,
okay? We're not opening
up the terminal. We're
not setting anything up.
Our orchestrator is doing
all of that for
us. We're just talking
to the O agent.
This is a powerful
multi-agent orchestration pattern. Okay,
so how does this
work? Let's just take
a step back. and
talk high level, how
does this actually work?
Let me be super
clear about something. The
orchestrator agent is a
orchestrator agent is a
custom agent, okay? Its
system prompt is completely
overwritten. Its tools are
specialized. It's designed to
manage other agents. Using
the single interface pattern,
you talk to your
orchestrator agent and it
creates, deletes, and updates
and manages your agents,
okay? In fact, we
can push this even
further, which we're going
to do in a
future agentic horizon lesson,
it can manage your
entire agentic layer. It
can call your ADWs,
can call your ADWs,
it can call your
prompts, it can call
your agents, it can
do it all. This
is why this is
the next level in
the agent scale framework.
Base, better, more, custom
orchestrator. This is agentic
engineering scale to the
next level. So what
else can we do
with this? This system
leans on a powerful
agentic framework. The incredible
part about this system
is that it is
interoperable with the entire
Claude Code ecosystem. What
do I mean by
that exactly? If we
hit control K, once
again, you can see
again, you can see
all of this metadata
we're going to break
down one step at
a time. But right
now let's just do
something simple. Create an
agent to run slash
question and ask if
our orchestrator and agents
can use skills. Okay.
We're gonna ask a
question. The orchestrator agent
doesn't do work outside
of what it's specialized
to do, which is
conduct and orchestrate other
agents. All right. So
we have our code-based
questionnaire agent that just
got spun up. It
looks like our orchestrator
decided this is a
simple task. So it's
just gonna run a
fast model to do
fast model to do
this. And she's gonna
understand running the question
prompt, let's focus in
on that, right? What
just happened there? We
were actually having our
agent run a slash
command, a custom slash
command, also just known
as a reusable prompt,
okay? Just by me
saying that, a whole
world of possibilities should
be activating in your
mind. We have access
to the entire cloud
code ecosystem here. We
have access to reusable
units of compute. we
have access to the
leverage points of agenda
coding. We can tap
into reusable prompts and
into reusable prompts and
we've taught our orchestrator
agent. Once again, we've
templated our engineering into
our orchestrator agent so
that it knows how
to run custom slash
commands for our other
agents, all right? Super
powerful, it's done already.
It's found the answer,
right? 20K context, one
cent, we have the
answer here. The answer
is yes, orchestrator and
agents can use skills.
It's telling us where
you can even see
it's consumed files, where
and how they figure
that out. Fantastic, right?
We are directly tapping
into a great agent
into a great agent
decoding ecosystem. We can
also do this, right?
If I type slash
prime, Guess what's gonna
happen here to our
primary agent? Our primary
agent is going to
run the prime command.
It's going to understand
this codebase. If
you've been following my
work for a while,
you understand what prime
is. This is a
user activated memory file
that gets your agent
focused on a specific
task. You can set
up a generic slash
prime, right? Like we
have in this code
base. This is nothing
new. You've seen this
before, right? Slash prime
here, just a simple
here, just a simple
prime command. We're setting
things up, read some
essential files, or you
can set up more
more important, more specific
prime commands like this,
right? Where you're specializing
the files, okay? Hopping
back outside the loop
here, your agent can
just run these, right?
Both the orchestrator and
of course our primary
agents, right? And our
agent bank. And so
you can see there,
it's just reading these
files. You're not going
to always want to
do this, but a
prime command is of
course gonna be useful
for your orchestrator agent
to give it a
high level understanding of
the codebase. But
the codebase. But
you can see here,
the risk of course
is we are loading
up the context of
our orchestrator agent. You
want to keep your
orchestrator focused on conducting
commanding other agents. Still,
it's super important to
mention we're using the
powerful suite of tools
that allow us to
use agents in an
extensible way. Okay. Using
an agent in the
loop is just the
beginning of what you
can do. Don't let
these other agent decoding
tools fool you. Cloud
code and the agent
code and the agent
SDK and the ecosystem
is far ahead of
the pack. It's not
just about the agent
loop or the model.
It's about the ecosystem
that lets you build
the way you need
to, to solve your
problems at scale. Okay.
In tactical agent decoding,
we break down moving
from in the loop
to out the loop,
all the way to
ZTE, where we can
put agents to work
at scale. The O
agent is a key
step in that transition.
And the Cloud Agent
SDK tooling is helping
us get there. It's
us get there. It's
helping us push this
forward. We have hooks,
we have prompts, we
have access to every
Claude Code feature we
want. We've got better
agents, we've got more
agents, and they're all
commanded by our O
agent, our orchestrator agent.
So we're missing one
big piece here, one
huge idea. What about
custom agents? Let's go
ahead and reset, delete
agent. There's only one
agent that's going to
know exactly what that
means. So let's go
ahead and go back
to auto-file mode and
to auto-file mode and
let's talk about specialized
agents. Our previous agentic
horizon lesson was all
about custom agents. So
can our orchestrator agent
incorporate that functionality? Of
course it can. It
can do anything we
teach it to do.
If we had command
K here, you'll see
something interesting. We have
slash commands, We of
course have our orchestrator
tools here that we've
been using and we
have agent templates. Let's
create a new agent
that is specialized. Create
that is specialized. Create
an agent with the,
and I'm just gonna
click this. Let's use
scout report suggests fast
template command it to
summarize all fields are
regex search looks at.
Let's kick this off
and let's understand what's
gonna happen here. We're
going to create an
agent based off an
existing agent template. You
can see this sub
agent template coming into
our create agent tool.
And check this out.
This regex scout exists
from an existing template.
What is this template?
What is this template?
It is of course
a custom agent and
it's coming right from
our agents directory. If
we type agents slash
scout fast, check this
out. We are in
the Claude agents subdirectory.
We are stacking up
on this powerful ecosystem
that already exists. Instead
of just using a
sub-agent here, we can
turn this into a
full-on primary agent by
blowing away the system
prompt and by giving
it custom tools. That
is exactly what we've
done here. This is
done here. This is
what sub-agents are. We've
just pulled it up
a level. We want
it to be a
primary agent that our
orchestrator agent can conduct.
You can't do all
this with a sub-agent.
You're locked in, it's
too narrow. By adding
an additional level of
agents, we can do
a lot more. It's
a lot more controllable,
okay? 6K context, there's
all the tool calls,
there's a cost, there's
a model, and there
we go, we have
a produced document, this
pattern is super important.
Our agents are always
producing a document that
can be handed off,
can be handed off,
inspected, review, so on
and so forth. This
is a key pattern
for multi-agent orchestration. Every
agent should produce some
concrete result. Okay, otherwise,
what was the point
in the first place?
Okay, so we see
in the executive summary
here, it searches across
10 primary fields, six
categories, and there it
is, right? So we
can just quickly see
that. And of course,
we can use this,
right? This is this
field here. If you
type in using tool,
you can see all
of our using tool
calls. If we type
in pre-tool use, you
can see we're filtering
on that now. Regex,
on that now. Regex,
Scout, You can see
we only have RegEx
Scout searches here, so
on and so forth.
As always, we have
our concrete results, right?
We can one click
into the results and
actually read this and
understand what it is
if we need to
hop into the loop,
all right? But of
course, we don't. We
have a great Peter
system. We can just
quickly look at the
results at a high
level and just move
on, okay? So I
hope you can see
some trends here, right?
My agentic engineering velocity
right now is insane.
It's insanely high. We
It's insanely high. We
have custom agents, built
for specific purposes, built
for specific use cases.
We can deploy at
scale over and over
and over. When their
job is done, guess
what we're gonna do?
Delete the agent. Okay,
that's it. Right? This
is the pattern. This
is the loop. Okay?
We build agents to
do specific work. Once
it's done, they're gone.
They're dust. Okay? Clear
all. Now we're ready
for the next task.
All right? Scale, scale,
scale, observability, orchestration. It's
all here. This is
all here. This is
the next level of
agentic engineering. We start
at base, we add
better, we add more,
we customize them, and
then we orchestrate all
of them. Okay, I
don't care what user
interface you use. Of
course, I'm gonna make
this available to you,
but the idea is
the same. We need
multi-agent orchestration, and the
orchestrator agent is one
way for you to
accomplish that task, all
right? There is a
feeling you're gonna get
once you get this
up and running, once
you start using this,
that is differentiated. I've
come back to this
come back to this
pattern. I explore these
patterns all the time,
right? But I'm here
sharing this with you
because this experience, this
DX, this developer experience
is differentiated. Something is
different about this combination
of UI, of UX,
of agent understanding and
agent communication. It's all
about the flow of
information between your agents
and understanding how you
can peer into the
core four to get
more, better, faster results.
We used a sub-agent
template to build a
new primary agent with
dedicated settings. We specialized
the agent. Let me
just go ahead and
open this up again.
And I just wanna
mention one big idea
here. If we just
collapse, course, prompt engineering
is the skill, context
engineering is the skill
inside of this agent
you know, in the
system prompt of this
agent, we have once
again, templated our engineering.
We have a dedicated
scout report, a dedicated
structure that we want
structure that we want
our agent to report
its results in, okay?
Templating your engineering inside
of all these different
types of compute, right?
Sub-agents, skills, prompts, reusable
prompts. It's all about
encoding the way you
engineer, encoding the way
you solve problems. There's
a key theme of
Tactical Agentic Coding. You
need to be putting
your engineering into your
agents. This is what
makes them special. This
is what gives them
your unique advantage. Something
your unique advantage. Something
kind of interesting to
call out here is
if you can do
this work, if you
can do your job
with an out-of-the-box agentic
coding tool or an
out-of-the-box cloud tool, how
defensible is your product
really? How defensible is
your work really? If
it's just one, two,
three, four prompts away
with zero effort, all
right? This is why
specialization, solving your problems
very well is very
important. Inside of my
code basis where I'm
deploying this, I have
so many specialized prompts
so many specialized prompts
and agents and tools,
right? Additional tools for
my orchestrator to help
them run my domain
specific system better than
anyone else can. Okay,
this is the key.
This is your differentiating
point, all right? This
is another advantage I
wanna concretely communicate to
you here. You always
wanna be templating your
engineering and understanding what
the core four is
with every agent you
spin up throughout your
prompts, throughout your system
prompts, throughout your ADWs,
throughout your chains of
throughout your chains of
compute, right? Whatever leverage
points of agent encoding
you are composing, you
need to embed your
engineering, right? the edge,
that is the advantage,
okay? So we have
been barely using our
orchestrator's potential. Let's scale
this up, let's deploy
a team. We know
that we can run
prompts in our orchestrator
agent, but the scale
in which we can
do this is not
truly understood. Even in
single agents, a lot
single agents, a lot
of engineers are barely
using their agent's potential.
Okay, I'm going to
use our orchestrator, scout
and build, create simple,
flat, colorless, gray pills
for the app header,
information tense keyword there.
This is a location
in the codebase,
active, running logs. This
is up here, right?
So the running cost
displays. So we're just
gonna create some simple
UI pills. This is
a simple one off
task. I just wanna
showcase this prompt to
you. We are now
going to get our
orchestrator involved in this
orchestrator involved in this
process. We're spinning up
a small team of
agents to accomplish a
task. Each context window,
each task of our
agent is going to
be focused. And you
can see here, this
prompt has triggered orchestrator
thinking. Okay, our orchestrator
is now thinking and
now it's running a
workflow. So there we
go. We have our
scout header and we're
going to have our,
you can see we're
going to create two
agents here, scout, and
our builder. So there's
our builder, there's our
scout and our scout
is going to get
to work here after
our orchestrator kicks it
off. There we go.
And you can see
here again, we're using
custom agents, okay? Specialized
custom agents at scale.
We can spin them
up and spin them
down with a single
prompt, okay? So there
it is. We're using
our scout reports just
fast and then we're
using a build agent,
okay? Of course, you
can guess what that
does. It's focused on
actually making the code
changes and making them
well, okay? powerful example
of multi-Asian orchestration. We
have agents doing work,
creating useful information sets,
creating useful information sets,
and they're going to
pass that off to
the next agent. Okay.
So we're talking plans,
we're talking logs, we're
talking results, we're talking
documentation, and then our
orchestrator chains it all
together. Look at what
our orchestrator is doing
here. It is actually
involved in this process.
Okay. So our orchestrator
is in a loop
sleeping. You've probably seen
this pattern. Your primary
agent will sleep, fire
off some other agents
to do some work,
and then it'll check
in on that. Right.
So this is a,
common agent decoding pattern
you can use. And
you can use. And
we're doing it with
our orchestrator agents. So
we're getting our orchestrator
involved here. We're scaling
up the compute to
monitor this multi-agent workflow.
And so every 15
seconds is going to
run check agent status
on the scatter to
see how the scatter
is doing. And so
you can see there
scatter has just finished
this work. We're not
going to get our
produced assets, right? Every
agent must produce a
concrete result. Otherwise, what's
the point? We can
of course dial in,
we can see the
summary there and it
knows exactly where to
put these exact files.
put these exact files.
Of course, we can
one click in, we
can understand what's gonna
happen. The main thing
here is that the
app header is gonna
have a couple items
updated, right? Problem statement,
execution summary, blah, blah,
blah, all right? Classic
agent decoding. Now our
orchestrator agent, still with
very minimal context. Keep
in mind how much
work this orchestrator has
conducted up to this
point, okay? And this
context still floating along,
it's because we are
indeed all of the
context, reduced, and delegated.
We have multi primary
agents operating the actual
agents operating the actual
work. Now our orchestrator
has handed the work
off to our builder
agent. Okay, very powerful
stuff there. There's another
command agent tool and
you can see, check
out this write up.
check out this detailed
write up our orchestrator
gave to our builder.
Okay. It is doing
some serious prompt engineering.
You can see the
work coming in there.
Keep in mind, these
agents are operating on
this project. They're operating
on themselves. Builder being
very precise because we
had a scouter look
for the changes to
make. Obviously relatively simple
make. Obviously relatively simple
UI change, but we're
putting a team of
agents to make sure
the job gets done.
If you can deploy
a little bit more
compute, to have more
confidence and more trust
in your agents, why
wouldn't you, right? Compute
can solve so many
of your engineering problems
if you put the
compute to work. Okay,
so here we are,
builder here doing some
thinking, right? We can
just dial in on
all the thinking of
our agent here if
we want to. And
of course we can
just specialize on just
our builder agent logs
here. If you just
wanna see the individual
tools, we can see
that as well. But
what we really care
what we really care
about most of all
is the results. Our
orchestrator thinking one more
time, still executing, doing
verification work, looks great.
Changes are in place.
It's gonna check the
syntax for us. All
this is happening for
us with our multi-agent
orchestration system, all driven
by our orchestration agent.
We have put together
three critical pieces to
unlock the next scale
of agentic engineering. We
have an orchestrator, we
have CRUD for agents,
so we can unlock
agents at scale, and
we have observability. These
we have observability. These
three design elements unlock
something special. And this
is what I want
to share here with
you today. Here's that
summary coming in from
our specialized agent. All
right, there it is.
There's the changes, 36
added, four removed. Click
into this and we
can see the We
now have that stat
pill and it is
working as expected. Let's
hop back out the
loop and just continue
to observe our agents
completing. We have a
response followed by a
stop. This is how
our orchestrator knows If
our orchestrator knows If
the work is done,
there it goes. Updating
its to-dos, it has
that as a tool
as well. And our
orchestrator, our agents, they're
working together. I think
you get the point,
right? We have multi-agent
orchestration. This is the
first true working example,
first true working paradigm
I've seen of orchestration
over long periods of
time for serious engineering
work where you can
actually peer into the
system. You can see
what's going on. If
something went wrong, I
something went wrong, I
could dial in right
here and understand why,
when and where and
who, right? What agent
messed up? Was it
our planner? Was it
our builder? Was it
the other agents in
this pipeline? I wanna
keep these examples concise
for you, but when
I'm working on this,
when I'm deploying agents
at scale, I'll have
five to 10. One
time I had 16
agents operating, completing work
at absurd scales, absurd
scales, okay? And there
are levels to this
game, okay? And I
just wanna show you
just wanna show you
maximum potential. I'm gonna
show you what you
can really do if
you invest in the
agentic layer, right? Make
no mistake, the multi-agent
orchestration, your O-agent, it
is a part of
your agentic layer. In
fact, it is the
key to unlocking how
to best organize, create,
and use your agentic
layer. We don't have
time for that here,
but we are going
to be diving into
scaling multi-agent orchestration and
connecting it to your
AI developer workflows and
AI developer workflows and
your agentic layer, all
right? The big advantage
here with the O
agent is that you
can use this long
before you have an
agentic layer, which is
really important when you're
first using this pattern,
when you're first using
these ideas. Okay. So
there's a summary, right?
Our orchestrator agent just
continued in that agentic
loop, checking the progress.
We have a live
feed going into our
database. We can just
tap into with a
custom tool that our
orchestrator agent can use.
And here we have
concrete results. We can
of course blow this
up a little bit
to see this a
little better. Obviously the
little better. Obviously the
work is done. We
have the pills there.
Okay. So let's deploy
one more task and
then let's talk about
operating in the gray.
Let's talk about the
realism around these types
of systems. I want
to talk off, limitations,
what's missing, and then
we'll talk about what's
next for Agentic Horizon
and what opportunity is
available for your Agentic
Engineering. Once again, the
agents are done, clear
all agents. And then
we're gonna fire off
another workflow pushing the
compute even further. Let's
go ahead and clear
all here. Our orchestrator
all here. Our orchestrator
is going to clean
up these agents for
us. There we go.
Command K, paste. This
is the last prompt
I'm gonna showcase to
you. Here we're gonna
do something a little
more complex, some more
UI changes. We want
our agent list to
collapse and we wanna
update our orchestrator chat
to go into small
mode when browser width
is less than 650.
We'll just be super
clear here and say
less than. Okay, we're
gonna kick this off.
And this is of
course going to fire
off an agentic prompt
designed for our orchestrator.
This is something that
a lot of engineers
don't realize. Once you
don't realize. Once you
build a custom agent,
you can then write
prompts, specialize for that
custom agent. Okay, detailed
for that custom agent.
This gets ultra, ultra
powerful. There's a lot
you can do with
this, all right? This
agent is gonna kick
off. It's going to
create a bunch of
agents for us. It's
going to deploy compute.
It's gonna handle this
problem for us, all
right? So let me
showcase that prompt. And
this is the big
advantage you get when
you start specializing your
agents. You can build
custom prompts that only
they can run. And
this should sound familiar
this should sound familiar
and very in line
with all the ideas
we've been discussing. You
get domain-specific expert agency.
through prompts. Here's how
this workflow works. We
have plan with scouts,
build and review. So
a three step workflow,
Tactical Agentic Coding members.
This should make you
think of something very
similar. It should make
you think of the
ADW. Okay. We have
a multi-phase step plan
here, three phases with
a final report. And
of course we have
a report section. We
have great consistent agentic
prompt engineering. You know,
these ideas, it's so
these ideas, it's so
important to just establish
these great patterns so
that you can get
to work and get
things shipped. Set up,
We're gonna create all
of our agents upfront.
If we hop back
into our tool here,
we can see that
we have all of
our agents. Our planner
is currently executing. It's
putting together all the
information that our next
agents will need to
actually accomplish this task.
Okay, so we have
a team of agents
built to accomplish a
specific task, each with
their own role. Our
orchestrator agent is of
course in a thinking
loop. There's our response
UI plan, check that
UI plan, check that
out. And you can
imagine that in our
plan prompt, Our agent
knows how we like
to plan. We've templated
our engineering and our
agent has access to
that. So if we
just close this, you
can see there we
just passed phase one.
So that was our
plan phase. So next,
our build agent is
going to spin up
here and start getting
to work. This is
a classic workflow. If
you're agentic coding, you
understand what's happening here.
The big difference is
we have agents that
we've spun up out
of nowhere with our
of nowhere with our
orchestrator agent, powerful primary
agents that we can
operate on, and then
our work can be
passed off to the
next agent, and then
the next, and then
the next. Look at
this, planning took 21,000
tokens. This is a
relatively small codebase.
If this is larger,
2X, 3X, 5X the
size, you can see
this going up. We
are constantly solving the
context management problem with
multi-agent orchestration. We have
a planner, we then
pass it off to
our builder and then
our builder is going
our builder is going
to hand it off
to our reviewer agent.
All right, so that's
this three-step workflow. You
can see our agent
plan complete. It's summarizing
that work. And now
our orchestrator is working
on phase two. Check
this out, right? The
orchestrator itself has written
out a comprehensive plan
for the builder because
it's understood the work.
Okay. It understands the
work that our first
agent has done. The
orchestrator is now a
part of connecting the
workflow, right? It's glue
for the workflow. I
think this is vastly
superior to agent handoffs.
superior to agent handoffs.
It's more superior to
a blind sub agents.
We have a primary
agent here that has
been given context. It
can reference other files.
It is less ephemeral.
We can reprompt. We
can run continuation prompts
through our orchestrator agent,
so on and so
forth. Right? So let's
just go ahead and
finish up checking out
this prompt, right? So
we have, our build
and then we have
our final, right? But
if we just scroll
back up to the
top here, right? We
are running an orchestration
prompt. So our high
level agent is kicking
off three agents and
off three agents and
it itself, you know,
through each one of
these steps has multiple
phases. It's going to
work through, through each
phase is going to
command, it's going to
check, and then it's
going to report. Okay.
And it's going to
do this through these
steps. And then we're
going to have a
final report. We have
a concrete, report format.
We want our agent
to communicate to us
in the way that
we would want to
be communicated with, with
another engineer. We want
it to be concise,
informative, information rich, but
also we want to
focus on actually getting
the work done. And
with this workflow, we
can do that. And
then we can have
a reviewer agent come
in at the end,
review the work so
that we know it's
done right. I'm not
here to try to
sell you some, sell
you some product, right?
You're going to have
this codebase available
to you. As soon
as you finish this
lesson, you can play
with this. You can
take it, play with
it, get it all
set up. This is
running on a neon
database. So if you
just create a neon
database or a local
Postgres database with Docker,
however you want to
do it, I'm not
here to tell you
how to set up
your multi-agent orchestration or
your multi-agent orchestration or
even that you need
to use this. Okay.
What I want to
do here is communicate
to you the next
level of agentic engineering.
It is very clear,
it's crystal clear that
multi-agent orchestration is a
key step in scaling
your compute to scale
your impact. It is
very likely you're gonna
see big AI labs
build out something like
this, okay? You're already
seeing some primitive versions
of this with the
cloud-based tool where you
fire off one agent
at a time, back
and forth, back and
and forth, back and
forth. You know how
that goes, okay? You've
seen that, we're gonna
watch this evolve. What
I wanna do here
is just communicate to
you the next paradigm
of engineering so that
if you want to,
you can get ahead,
you can push your
engineering. And at the
very least, you can
take some of these
ideas and roll it
into your own work.
Even without the orchestrator,
when you're operating in
the loop with your
basic agent, your basic
codex, Claude Code, Gemini
CLI, whatever agent you
like to use, you
can build out more
powerful workflows than you
powerful workflows than you
think you can. You
can command more compute
to get more work
done. If you wanna
take this to the
next level, multi-agent orchestration
is waiting for you.
Now, there are of
course trade-offs to this.
The real trade off
here, the real balance
is that this takes
time to build, right?
Very obviously multi-agent orchestration
and the O-agent cost
upfront investment and you
have to manage your
orchestration agent, you have
to manage the plumbing,
the database, the WebSocket
the database, the WebSocket
connections. It can be
a lot to coordinate.
If you know what
you're doing, this application
is relatively simple. We
have WebSocket events coming
to the front end,
we have some HTTP
events, we're using the
agent SDK and we're
saving it to a
database. But things can
and will get complex
This is another piece
of your agentic layer
you'll have to maintain.
So that's the big
trade-off. Is this worth
investing into? I think
the answer is a
very clear yes. You
want to have, even
if you don't use
this, the key here
is that you want
to have some type
of Outloop agentic coding
of Outloop agentic coding
system. Outloop agentic coding
is ultra key, right?
You want to have
multiple modes of engineering.
If you need to
step down into the
loop, which I, had
to do when building
this out, right? I've
had to do it
multiple times. You can,
right? Hop in the
loop, hop in the
terminal, increase your presence,
right? Write those back
and forth prompts. That's
fine. I fully recognize
that is a valid
mode of engineering, but
more and more, there
is work you should
not be doing. You're
wasting your time. The
wasting your time. The
right way to think
about engineering now is
the agentic way. You
want to be thinking
about scaling your agentics.
Remember, tactic eight, prioritize
agentics. More than 50%
of your time as
a rough guideline should
be spent investing into
your agentic layer, into
your agents, into the
system that builds the
system. Okay? Here, very
clearly with a multi-agent
orchestration, we have a
powerful version of that
that works even before
you get concrete ADWs
you get concrete ADWs
inside of your code
base. So there are
some things missing here,
some future directions that
I may take and
that I may share
inside of Agentic Horizon.
Human in the loop
decision points, are gonna
be very critical. You
can see a simple
interface on top of
this where your agent
wants to ask you
a question, your agent
wants to prompt you.
This is a key
point in agent engineering
where your agents start
asking you questions versus
the other way around,
okay? That's missing here.
Better management of the
orchestration agent. It's gonna
be a great direction
be a great direction
to go. I should
be able to just
quickly start a new
agent or reference previous
orchestration agents and their
related agents so that
we can work on
multiple systems, multiple code
bases throughout single interface
with a single UI.
Right now, if we
hop into the code
here, this server is
actually pointed toward one
specific codebase at
a time. I think
This is a great
place to start, but
we can push this
further. Something else that's
missing. If we want
to fork an agent's
context window and basically
duplicate an agent from
a specific point, this
is one tool away.
And thanks to the
Cloud Agent SDK, it's
a few modules away
from being built out.
We should be able
to fork context windows
and fork agents at
any point in time.
One big piece here,
and frankly, the highest
return on investment is
gonna be some really
well-built out autocomplete and
tab functionality basically a
dedicated language model, likely
a cheap, fast model
to help out with
prompt engineering right here
in the terminal with
in the terminal with
auto completes for agents
slash commands, templates, tools,
so on and so
forth, right? Just to
help speed up agent
decoding even further. Okay,
it looks like our
builder has finished its
work. This is fantastic.
You can see again,
all the work done
one click away, right?
Result oriented engineering in
a single interface, right?
Our Outlook system is
very, very powerful here.
A lot of systems
rely on pull requests.
That's great, but it
misses a lot of
the story. It misses
a lot of the
journey, right? We get
all of it here
with our observability interface.
So our agent's finished.
Let's see how it's
done here. Fantastic. So
you can see that
that worked, right? If
we go into large
mode here and let's
shrink right around, at
around 650, we should
see collapse. There it
is. Nice. So you
can see our shortened
windows and then it
sizes up and you
know, we can collapse
this and just see
our collapse mode here,
get a little bit
more space. That's what
that looks like. So
this feature shipped, we're
now having our reviewer
agent confirm that the
work was done. So,
work was done. So,
I hope you can
see how powerful this
is, right? Three agents,
dedicated, 21K, 17K, focus
context windows, one agent,
one prompt, one purpose,
focusing in on tactic
six, let your agent
work and then let
it go home. Big
labs are going to
be doing something like
this, right? You already
see it. with cloud
coding tools, these are
coming, all right? And
there's gonna be many
varieties of this, right?
There's gonna be your
Vibe coding one-shot prompt
tools, and then there's
gonna be your legitimate
engineering tools. Obviously, we're
engineering tools. Obviously, we're
gonna lean super hard
on the legitimate software
engineering out of the
loop agentic coding tools
like this system, but
these are coming up.
We want to have
a spectrum of tools
we can use. More
specifically, we wanna have
a dedicated solution for
solving our domain specific
problems with our specialized
agents. Okay, this is
the agentic engineering advantage.
You can build agents
that know your problem
better than anyone. Okay,
better than any cloud
better than any cloud
tool, better than any
team. is the advantage,
okay? And you can
scale it hard now
with the multi-agent orchestration
and the orchestration agent,
all right? Now, there's
a big missing piece
here, another kind of
final missing piece. How
does this plug into
deterministic code? How does
this plug, right now,
this is very agentic,
right? We've dialed up
the autonomy knob here
quite a bit, which
is great, that is
the direction, but we
also have a missing
piece of deterministic code.
We're missing our AI
developer workflows. Okay. This
developer workflows. Okay. This
is the big missing
piece. And this is
something that we will
be building and I
will be showcasing in
upcoming agentic horizon lessons.
It's going to fit
in very well with
the voting. Thank you
for placing your votes.
That information has been
really great for guiding
upcoming lessons. I think
if I do another
large heavy hitting course
like this, who knows
if I will, but
if I end up
doing another one, I
will definitely incorporate your
your word, your ideas
into upcoming lessons. I'll
ship some lessons and
I'll let the ecosystem
I'll let the ecosystem
of great engineers that
are watching and viewing
this. I'll let you
make your concrete vote
so that I know
exactly what you're looking
for. We're going to
have a lot of
great overlap. I digress.
ADW plugs into this
workflow perfectly. I already
have mocks and I
already have agents building
a version of that.
More on that. in
the future. I'm not
just trying to sell
you some fake, unrealistic
vision of a perfect
out loop agent decoding
system with ADWs running
left and right, doing
all your work for
you, right? We have
to be realistic, right?
Engineering happens in the
gray. It happens in
gray. It happens in
the messiness of it
all. There's a progression
to this. You know,
with the multi-agent orchestration,
with the O agent,
this works in the
loop and it works
out the loop. I'm
not trying to just
sell you an endpoint,
an end destination with
tactical agent decoding and
agenda horizon. We are
working step by step
to get there. And
this is a critical
step. This is agents
at scale. Once again,
orchestration agent allows us
to CRUD agents, which
lets us have agents
at scale, and then
we observe it. Okay,
we can quickly observe
we can quickly observe
everything our agents can
do. And we are,
of course, being results-oriented.
Every agent reports a
concrete result of what
it just did. The
orchestrator agent is the
first pattern where I
felt the perfect combination
of observability, customizability, and
agents at scale. In
this lesson we spun
up many, many agents
with dedicated focus context
effortlessly. Multi-agent orchestration is
the name of the
game for the next
level of agentic engineering.
It's not perfect. There
are issues, you know,
are issues, you know,
in this codebase,
in this entire methodology
of operating. I fully
admit to that. There
are trade-offs everywhere. There
always are. But it's
clear this pattern is
viable for scaling your
agentic engineering. Give this
a shot. You can
see our reviewer just
came in with the
review. We can one-click
into the loop, understand
what's been done, and
then we can get
out of the loop,
go back to the
high level. We can,
of course, clean up
our agents with a
single command. We can
control it all and
manage our compute better
manage our compute better
faster than ever before.
Give this a shot.
And if you see
big AI labs picking
this concept up, remember
where you saw this
first. Great work here.
I hope the gears
are turning in your
engineering mind. The orchestrator
agent private codebase
will be available to
you. Link available in
your loot box. Any
release or system that
enables you to increase
the information rate between
your agents and your
work requires your attention,
requires your focus. The
orchestrator agent is one
orchestrator agent is one
of those systems. Give
this a look. Link
in your loot box.
I'll see you in
the next Agentic Horizon
lesson.