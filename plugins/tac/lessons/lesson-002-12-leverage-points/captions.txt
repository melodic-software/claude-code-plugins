# Lesson 2: The 12 Leverage Points of Agentic Coding
# Video Transcript (47:15)
# Source: https://agenticengineer.com/tactical-agentic-coding/course/the-12-leverage-points

Welcome to Tactical Agentic Coding. This is lesson two. In lesson one, we set the stage. In lesson two, we start performing. In order to become an irreplaceable engineer, we have to stop coding and learn to build systems that can operate on our behalf. To get there, We need two things, a framework that won't change over time and a tactic that shifts how we engineer from AI coding to agentic coding so we can maximize not what we can do, but what our agents can do.

Just like with AI coding, Agentic Coding is easy to start, hard to master. All the low hanging fruit is getting chewed up. It's time to do the smart work, not the hard work to get asymmetric return on your engineering. It doesn't matter how much compute you use or what tool or model you choose or what new innovation was just released. Some aspects of engineering never change. When there are massive trend shifts and revolutions in the tech industry, something incredible happens. If you pay attention, you can see the aspects that never change and you can place big bets on them.

One of these aspects of engineering that never change is resurfacing in a big way. It's the software development lifecycle. Throughout tactical Agentic Coding, we'll break down the software development lifecycle into five concrete steps and use them as our framework for success. This compressed, focused version of the software development lifecycle is built for phase two of the generative AI age. Plan, code, test, review, document.

Over the next seven lessons, we're going to augment and automate key steps so that your agent ships on your behalf. When I say your codebase will literally run itself, I mean that. We're not here to write bigger prompts and iterate back and forth and back and forth. We're here to dial up the autonomy knob all the way to 11. We're here to become Agentic Engineers. How well you do this determines your progression as an engineer in phase two of the generative AI age.

This lesson focuses on three key topics. We'll break down a new tactic that shifts our mindset from AI coding to Agentic coding we'll then introduce the 12 leverage points of Agentic Coding and then we'll discuss how to measure your success so that you know you're improving so we're betting on the software development life cycle as our framework for success now what's our lesson two tactic that will drive how well you hand off work to your Agentic Coding tools throughout the software development life cycle adopt your agent's perspective.

This tactic is critical for high leverage Agentic Coding. Why is that? Your agent is brilliant, but blind. With every new session, it starts as a blank instance. Agents are ephemeral, no context, no memories, and no awareness outside of what you give it. And when all the work is done, it resets back to zero. If you want your agent to perform like you would across your codebase, agentically, it needs your perspective. Your agent needs the information, the tools, and the resources you would use to solve the problem at hand.

Let me say that another way. Your agent needs your context, your model, your prompt, and your tools, the core four this is what's so special about the core four it lets your agent operate just like you reliable tool calling agentic behavior and intelligence are no longer limitations thanks to modern llms and agents like clog code by consistently adopting your agent's perspective you close the gap between what you can do and what your agent can do. Only by doing this will you make a key transition into high leverage Agentic Coding where it's not about what you can do anymore. It's about what you can teach your agents to do.

I hope you can see how important this tactic is for Agentic Coding. Now that brings us to an important question. How can you give your agent everything it needs to succeed. We do this by using the 12 leverage points of agentic coding. There are 12 leverage points of agentic coding you can use to maximize your agent's ability to execute your engineering work. Remember, the goal is to become an irreplaceable engineer by building increasingly self-operating machines.

In order to get where we're trying to go, in order to become irreplaceable, we need high leverage agents that can do real engineering work in one shot that we can run back to back to back to back. Right? We want the longest hot streak possible of success. When you stack up these leverage points, Agentic Coding success becomes inevitable. Now, what are these leverage points? Let's break them down and look at a few of them in action.

There are two types of leverage points in agent and through agent in agent leverage points contain the core four. These are in the agent because they're always with your agent context, model, prompt, tools. We're very aware of these. We're very comfortable with these ideas. We use them all the time, every day to get engineering work done. Through agents are external levers that eventually interact with your agent that have massive impact on your success. They typically flow through the context window. Here we have standard out types, documentation, tests, architecture, plans, templates, and ADWs.

Let's shift from theory to some practical engineering using the 12 leverage points of agentic coding. Let's go ahead and open up the terminal. Here we have the lesson one code base. Let's clone in TAC2, link available in your loop box below if you wanna follow along. TAC2 VS Code. So before we do anything, let's open our Agentic Coding tool of choice, ClaudeCode. In order to fully transition into Agentic Coding, we need to lean on our agent as the primary interface in which we do engineering work.

Let's have Claude code teach us about this code base and run the installation steps, which install the front end and the client. We can do this all with one prompt. We can type slash install. Out of the gate, we're using a custom slash command. This is a reusable prompt. If you open up dot Claude slash commands, you can see all of the built-in baked in reusable prompts inside this code base. If you open up install, you can see exactly what just ran there. Very simple, seven line. We're reading and executing an entirely different prompt. And then we're having Claude Code install the front end and back end dependencies.

We're using a powerful pattern of running prompts inside of prompts. This is no different than passing a function inside of a function. We can open up the prime method and you can see exactly what this does. Get else files. And then we read the readme. This is how our install command knows how to install the front end and back end dependencies. If we look at the Claude Codes output here, we can see that's exactly what's been done. Look at all this engineering work that just happened agentically doing things one step at a time until it's all complete.

Let's open up the readme and let's get our environment variables installed so that we can run this application. This is going to be in step two here. Setting up your configuration. We open up app server. We want to set up a dot environment variable file here for our server. I'm going to go ahead and copy the send. Of course, make sure you don't leak this to anyone. All right. So I have my environment variable there. If you look at the sample, you can see we just need an open AI key and the anthropic API key.

All right. And then we can run our start setup script. This will kick off both the front end and the back end. We're just going to open up a brand new terminal window here. Let's kick off our front end and our back end with this script. Check out this file before running it. If you're running on Windows, make sure, of course, in WSL. And you can see here, this kicks off both our front end and our backend. So let's go ahead and close our files here and let's open the browser.

What exactly are we running here? Here we have a simple natural language SQL interface. If we hit upload data, we'll start with a sample data set. We'll click the product inventory. This will create a new table inside of our in-memory SQLite database. So now we can do something like this list top five products by price. We can kick this off. And of course our application will take that natural language query, convert it into an SQL statement, and then return the results from our database. This is a simple, beautiful, classic language model application. This code base will make a great playground we can use to showcase the leverage points of agentic coding.

If we open up our prime command, you can see cloud code was asked to run the commands, read the file, and then summarize your understanding of the codebase. That's exactly what it's done here. We have a front end, backend, AI integration, and a database. Fantastic. Let's turn our attention to the in-agent leverage points of agentic coding.

Now we're already familiar with the in-agent leverage points. This is just the core four, right? The context, the model, the prompt, and the tools. But let's briefly touch on tools. We'll gloss over the context model and prompt so we can focus on the heavy hitting through agent leverage points. So with Claude Code, the tools are embedded in its system prompt. That means we can quickly see the available tools with this prompt. We can type slash tools and you can see here we have another baked in prompt template we can just keep reusing.

If we open up that file here tools dot markdown, you can see the exact prompt that's getting run here. So let's go ahead and copy this out. These are all of the baked in tools. In order to really use tactic to adopt your agent's perspective, We need to see what our agents can see. We need to know what they can do. Tools, as you know, give your agents the ability to act. But if you don't know the tools your agent can use, you can't maximize your agent to its highest capability.

For instance, did you know that the bash tool here has a timeout? So if you want to run a long running bash command and feed the output into Claude Code, you can set the timeout. There are many little hidden kind of secrets inside of every single tool, and it always helps to see the definition and it always helps to know everything your agent can do. You can see we have delegation tools, bash tools, we have reading tools, We have writing tools and web tools. Notice how these represent the essential engineering commands. They can crud create, read, update, delete a codebase just like you and I can. We can also add arbitrary tools with MCP servers. We'll use several mission critical MCP servers in future lessons for now. Let's focus on the leverage points.

Now this is where things get interesting. We already know about the core four with tools as the latest addition. Let's look at our through agent leverage points. Let's start with standard out.

Your agent can only see what you let it see. Standard out is the response from any command you run. Every time your agent runs a command, as we saw here, it's always getting some type of output. Some error, some response, some lines of code red, some directory structure, right? It's all standard out. This means that clear logging throughout your applications, your commands and your scripts can guide your agent to success.

Let me show you exactly what I mean in this codebase. If we open up the application here, we can upload data and inside of the codebase, if we open app client public sample data, we have a couple of files here. Let's open this in an explorer. All right, so we're gonna drag and drop this over. And you can see here we have an error, error converting CSV to SQLite, and there's some error message.

Now we can see this. The real question though is, can our agent see this? If we hop back to our IDE, if we go over here, we have a massive mistake. Not only do we have bad code, we have bad agentic code. Our server is not printing out the error at all. There's no way for our agent to see what's going on. This is what it looks like when standard out is completely missing. The issue is getting bubbled up all the way to the front end without any trace throughout the server or the client server. So let's fix the code that enables our agent to fix the issue.

So open up code, I'll boot up a brand new agent here. I'll type Claude, I'll type Prime. So we're just running that Prime command. We don't want install, we've already done that. So there it goes. Once again, just rerunning this small, short, but powerful agent workflow It's running Git LS and it's reading some files. And now let's run this. In our directory here, we can see app server. If we scroll down here to server, we can see exactly what our API endpoints look like. If we collapse all the code here, you can see we have a bunch of endpoints that if we drill into it, they're not giving any standard out, right? These are all just raw responses. This is bad agentic code.

Why is that? It's because our agent can't see anything. It can't help here at all. So we're gonna run this prompt here. I'm going to get the reference to this file. I'll type app. I'll use the at symbol for references. I'll search for server.py. I'll tap complete this. And then I'll say, make sure every exception, all exception details, make sure every successful response before returning.

Okay. And so what we're doing here is I'm not actually fixing the issue. I'm setting up my codebase. So that my agent can resolve the issue. Okay, we're going into Yolo mode here. We don't want to be constantly watching everything that's going on. We want our agent to do the work for us on our behalf. So here we go. Just doing a quick code review. You can see exactly what's happening here. Now we're printing to standard out both the error case and the success case.

Okay, this is a big change. Now, if we hop back to our start script, cancel the front end and the backend and then boot them back up We can reopen our front end here, refresh. And now you can see we have this success. If we re-upload this error, right? If we hop back to the server, we now have an error message getting traced to standard out. Fantastic.

Okay. So what we're doing here is we're building up a system for our agent to solve problems, right? We're updating our codebase to communicate information to our agent. So this is great. Now what we can do is close the server here and open up a brand new agent instance. Let's open up a new cloud instance. Now we'll do something great. Let's go ahead and prime our agent again. We wanted to understand the structure of our application. The prime custom slash command is super, super important. This in combination with the claw.md lets your agent quickly get ramped up with information about your codebase.

We'll talk about that leverage point, the documentation leverage point more in just a moment, but you can see our agent is primed. Now I want to run the following. I want to say scripts start.sh, 300s. So now we're kicking off our start script inside of our agent. Okay. Inside of the current version of Claude Code, it only shows the first parameter, right? Which we know from looking at things from our agent perspective, if we search for the bash command, the first command is of course the command that we want to execute. Okay.

So we know the tools our agent has access to now let's put it to work. Let's really use that leverage point. So it's running this right now. That means it has access to standard out upload data. And let's drop this in here once again. Okay. So we have that error. And now we know for a fact that our agent has seen the error. From our agent's perspective, it is seeing the standard out from the start script, which shows output from the server and the client. Fantastic.

So now I'm going to stop running this and then I'm just going to prompt any issues with the server. Now we know there's an issue, right? But we're just validating it with our agent here. Let's see what it comes up with. There you go. There's an SQL error trying to execute this likely contains special characters like parentheses that aren't being properly escaped or quoted. Fantastic. Our agent can now see everything that's going on. It can resolve the issue on its own.

Okay, so we don't have to say much here. We'll just say resolve colon replace bad chars and escape. And so this is the power of standard out. Now our agent is going to read all the files it needs to and update the code so that doesn't break. Let's go into yellow mode here. All right. There's our new sanitized table name method. And now our agent is just doing all the work for us, right? Making sure agent can read standard out is a massive leverage point.

If you're working on a codebase that produces tons of standard out enough that would overload your agent or blow up your agents context window, you have a few options. You can create a dedicated per session log file that your agent can just read after the fact. Or you can, of course, clean up your log files that are likely too much for a human to read anyway. Or, you know, your last option here is you can set up your logging level to only log warnings and errors. Although, you know, I will say warnings and errors are only part of the story. You really want your agent to have the full standard output so it can really see everything that's going on in your application.

Just like we did here, if you give your agent the top level, it can at least know what methods are involved with the issue, which drastically reduces the state space. It reduces all the files, all the complexity that your agent has to run through to narrow down where issues are. Okay. There's a small codebase, so it could easily do that. But when you're operating in real codebases in production environments, you're going to have tons of files and you want to narrow down the scope of where your agent has to look. And one great way to do that one high leverage point of agent decoding is standard out.

All right. So we have things working again. Instead of running this by hand, I'm just going to hit up a couple of times and kick this off again. If there are any additional issues, I want my agent to be the one managing them. All right, so we're gonna fire that off again. Refresh the server, upload data, and let's actually delete our previous database file. There might be some issues there. We'll hit upload data, finder, drag and drop this in, and bam, look at that. We have these characters escaped. The issue's been resolved. We can say latest delivery. Okay, we'll hit query, and now our code's going to run as it should. Check this out, that's our latest delivery. Very cool stuff.

Now let's talk about another key leverage point. You've likely heard about how types and type languages reduce bugs, but why are they so important for agents? It's because types tell a story about how information travels throughout your codebase. When you have dedicated types in your application, you create a traceable flow of information your agent can follow, right? In fact, you can do something like this, right? Let's open up our type file here. Let's go to data models. Let's collapse. And let's just copy any one of our data models here, right? Let's copy the database schema response and then we'll prompt this.

I'm going to do a new Claude instance because I don't want Claude to have any context about what's going on here. All right, so we can say, show me how this type flows throughout the application, detail functions, files, and purpose. And then I'll just give it a format here. So I'll say file, new line, file, function dot dot dot. Right. So it can just continue the pattern. So I'll fire that off. And now our agent is going to trace this throughout the applications. You can see here it's firing off a task.

What does task do? Let's go ahead and look at our tools, right? Because we know exactly what our agent can see and do. We're thinking from our agent perspective. It is a sub agent for a keyword and file searches. It's firing off a sub agent to do work for us. All right. So we're getting a bunch of commands fired off here. You can see we're searching, check out the search, right? Pulling together all the instances, all the locations of this type.

To be clear, when I say types, I'm talking about classes, exceptions, interfaces, and all typing structures that represent a concrete piece of information in your codebase. Okay, so it's finished 26 K tokens, seven tool uses and check this out, right? We have a top to bottom flow of this type throughout the application. Okay. Just how you saw our agent searching here, This is how you can use types to track the flow of information throughout your application, right? This is a critical leverage point of agentic coding. This gives your agents the ability to look at flows of information throughout your code base.

All right. So we go from data model, servers, types, client, and then we have it detailed inside of our original spec file. Remember that types are IDKs information dense keywords. They point to exact locations in your code base and represent the flow of a specific type of information. You've likely done this where you copy a type or a class and then you search throughout the entire application and it tells you where all instances of this type is, which tells a story about the data and an information flow that you and now, more importantly, your agents can follow to deliver on engineering work.

Okay. Now let's talk about a really important leverage point architecture. Code-based architecture is a critical leverage point for agentic coding. Let me give you a dead simple example to showcase this. Inside of this application, if you open app, we have an architectural decision that cuts all possibilities in half for our agent. Can you guess what it is? It's looking right at us, right? Client and server. Because we have these separated, this one simple decision makes it easy for our agent to cut all of its work in half when dealing with the client or the server.

Okay, this is super, super important. It might seem simple, but three simple codebased architectural decisions will change how much time your agent spends just spinning, trying to figure out where everything is for the nth time. Remember, we're going to boot up agents over and over and over. We're talking hundreds and thousands of times. This is why we have to ask ourselves, how easy is it to reason about the structure of our codebase. How easy is it to understand how to operate your codebase and run different commands, right? If it's hard for you, you should assume it'll be hard for your agent.

You know, it's not that codebases can't be complex. They will be complex. Successful codebases. If your application tool or product is successful, it will grow by nature, right? The best preventative action against this is consistency. No matter how complex If you reuse the same patterns, folder structures, function names, file names, comment structure, your code base will be consistent and consistency is a powerful actor against complexity for both humans and for agents, right?

And this is something that It's so important and widespread that I've called this the agent navigation problem. Every time you boot up a new agent, it has to explore the codebase, right? Even with our prime command, right? If we open up our prime command and it understands at a high level, right? We can always just copy this and see what our agent sees, right? New terminal here, paste, get LS files. You can see what this is giving your agent, right? You get a good high level overview of where everything is, but this is just a starting point. Your agent still has to look through files, figure out where things are, and navigate your codebase. Your architecture stacks up very, very quickly for you or against you, okay?

I'm not gonna invent a complex code base to showcase this leverage point because you probably already have one. You're probably already operating in a complex code base where things fall apart somewhere in the application structure. Okay. I'm just going to list off a couple of important things that you should be doing in your codebases to help redesign it for your agent. Okay. More and more, it's going to be our agent operator codebases, not us. Right? So we need to build for them. We want our codebases to be token efficient.

So I'm just going to run through some here. You'll also have a concise list in your loot box below. Don't forget, we're stacking up a bunch of important loot for you. To help you quickly connect and reconnect with these ideas over time as you're doing real engineering work.

What are some of these items? What are some ways we can be consistent throughout our codebased architecture?

Use clear entry points, no matter what service it is, right? Server or client, right? Make sure it's clear where it starts. You saw we had the server.python file very quickly. Our agent knows to look for this main file to get started with the server. Okay. Use clear entry points, use constant files for unchanging information, use types, classes, and structures, use meaningful and verbose directory, file, type, class, and variable names.

Remember that everything you name can be an information dense keyword. If you start muddying your types and your data models and you call something, you know, something even like this, right? Query request, query response, not that good, right? This is one of those words that's like, Data request, okay, terrible, terrible name. There's not a lot of information here. If your agent ever wants to search for data or just request, it's cooked. Use these information dense keywords, name things, be a little bit more verbose and direct.

You wanna avoid large file sizes. I like the limit of 1000 lines as a loose, you know, good max file size to have great code based architecture. You want to have these markdown files, right? These read me's or these Claude.mds, whatever the agent specific documentation file is. You want to have that spread throughout your code base available whenever you need it. You can see we have it here. We have it in our tree. You really want these inside throughout your applications. We're going to be building these out as we go along in tactical agent to coding.

All right. You want to separate your services to make things really clear where things are at a high level. Stick to one responsibility per file. You want to sync your test file. If we open up the server here and we go to tests, right, we can see our tests represent the exact same folder structure as our server, right? We have core and we're testing everything in the core, right? So you want to mirror these. It makes it really easy for your agent to see and write tests. Obviously, we're getting to test in a moment here. That's a really important high leverage point of agentic coding.

There are many ways to organize your codebase. The main thing is that you want to make it easy to navigate. By making it consistent. Refactoring your codebase for your agent is a great idea and is the refactor that will pay you massive dividends. But don't refactor yet. In future lessons, we'll cover how to organize key agentic assets in your codebase without your agent and most importantly, with your agent, right? Your agent is going to be helping you organize build and document everything in your codebase moving forward. Consistent architecture has a massive long-term effect on your ability to improve your Agentic Coding.

We'll discuss measuring the success with key KPIs of Agentic Coding after we break down a few more leverage points here. We're not gonna deep dive into all these here. Many of these points have their own dedicated lesson. So let's talk about documentation. This is a big one. We have an entire lesson dedicated to docs, tests, and plans. So we're not gonna deep dive into these, but this is an important leverage point, right? It'll make or break your success.

Documentation is really simple. There are two types, internal documentation and external documentation. AI docs is a dedicated folder specifically for our agents. You don't want them making web requests every time they have to look something up. Just get it local, get it right here so you can write plans and do work when you need it, if you need it. Documentation and codebase architecture overlap a little bit. There are tools like RepoMix and other Git related tools that help you pull in open source codebases and make web requests. If you remember here, if we go back to our tools, Claude Code does have web fetch and web searching tools. This is just a critical tool for engineering, which is why they baked it in to the agent.

We have, of course, tests. Tests are mission critical. Let's open up app, go to server, and you can see here we have nice starter set of tests here in our codebase. Let's make this super clear. Your agent will make mistakes, okay, just like you. Your agent is bound to make a mistake at some point. The only question is, does it have the right leverage it needs to correct the mistakes? This is where testing comes in. Your back ends are the easiest thing to test that offer massive leverage on your Agentic Coding. And of course, our tests are spitting out information right to standard out so your agent can pick up on them.

Okay, so if right here, I just ran bang to run a bash command, UV run py test, Let's go ahead and CD into the right directory here. We can just run this, right? So UV run py tests, make sure we're in bash mode here. And you can see here, we are kicking off all of our tests, right? So all the output just ran and fed right into our agent. Everything pass, so there are no issues. If there was an issue, for instance, remember we just added this new functionality to our agent, we can have it execute the tests and then improve on them right away.

You can see where this is going. You can create self-validating loops. These are called closed loop structures. This is where we let our agent write the code itself by getting a concrete feedback loop. If you're not writing tests, you're leaving massive leverage on the table. This used to be a negotiable and a debatable. Should startups use these? Do engineers just starting out need to write tests? right test. That time I think has completely passed.

If you're not writing tests, you're probably vibe coding. And at some point, if you want your application to actually be useful, to actually scale with your agents, you need tests so that they can self-validate their own work. This is one of the highest leverage points of Agentic Coding. If you're not writing tests, this is probably the first leverage point you should go after right next to standard out. We'll dig into testing in future lessons, right? Backend testing is obviously a lot simpler. We also want front end tests. We want our agent to be able to, you know, really look at our front end to see the results of its work. We want it to be able to click buttons. We're going to look at both front end and back-end testing with our agents throughout tactical Agentic Coding.

Let's talk about plans. So this is a popular high leverage point of agentic coding. If we open up specs, we have the initialize codebase plan here. And so you can look at this, you know, it's some 750 lines long, lots of details, you know, going into code examples, front and back-end types, high level, so on and so forth. Most engineers don't spend enough time communicating what they want done.

Put simply, Plans are just prompts. Put accurately, plans are how you communicate massive amounts of work to your agent. This is how we scale up our work. This is how we do more in less time. And as you may have noticed by looking at this, there is no way that I sat here and typed out 700 lines of a plan. We are going to be planning with our agent. We're going to showcase how you can take your high level, low information, frankly, bad prompt, hand it to your agent and let it generate the first draft of your plan for you.

Okay. Planning is the first key step of the software development life cycle. You need to know what you want. You need to define it and your ability to communicate that information is all about how well you write your plans. If you can do the planning step well, which we'll discuss in our next lesson, every other step of the software developer lifecycle we're gonna be augmenting and automating falls right into place, but it all starts with a great plan. It all starts by communicating with your agent. This is a fundamental principle of AI coding that translates directly to the superset of Agentic Coding. The plan is the prompt and that means great planning is great prompting.

And so that leaves us with two more leverage points. We have templates and ADWs. So this pushes us to the highest level of abstraction inside of our codebase. We played with a couple templates. Really, these are just reusable prompts. There's nothing we're templating out. These are prompts we can reuse and pass information into. To use our precise language, these are agentic prompts, right? Prompts that can fire many tools thanks to Cloud Code, right? Thanks to Agentic Coding tools.

You saw how much work we did. Slash command, slash command, slash command. This is a code base with empty set of slash commands. Just to be super clear, you want many, many, many commands that help you do real engineering work at the drop of a single slash command. All right. We're going to be using these a lot throughout tactical Agentic Coding.

ADWs, aka AI developer workflows, are the highest level of abstraction. ADWs are created when you combine one or more agentic prompts right out of the commands directory and then you wrap it in arbitrary code and then you kick it off autonomously with a trigger. OK, here we're going to be using in ClawedCodes programmable mode. If we close out of this agent, type Clawed-P and then we type slash tools, right? This is programmable mode. We're running this right from the terminal, not in iterative mode, right? I'm saying do this work, call this command, whatever happens, return the result.

You can see here, it's done, right? This is what we're gonna be doing inside of ADWs, AI developer workflows. This is where real engineering work can happen autonomously. This is the leverage point we'll use to automate the software development lifecycle so well that your code base literally runs itself. Every tactic and concept from each lesson pushes us toward this final leverage point, ADW, the AI developer workflow. Okay. This is prompts combined with code, combined with a trigger so that it all runs itself.

Now, Don't worry if it feels like we've breezed through some of these leverage points. We'll be using these in every lesson moving forward. These are going to come back up over and over and over. Okay, let's talk about how to measure success and round out this really important lesson. Fantastic work so far, by the way. I know there's a lot of content here. We're working through a lot of key ideas, but this extends the groundwork we're setting and lets us get in the right headspace to transition from AI coding where we're prompting over and over iteratively, right? To real Agentic Coding where our agents are really doing the work.

Okay. So let's talk about KPIs. So how do we know we're actually doing things right? How do we know we're improving? Let's go ahead and just crack open a classic markdown file and just take a look at this. Okay. How do we know we're improving as Agentic Engineers? We have four KPIs. There are just four numbers that make up your Agentic Coding key performance indicators, right? We have size attempts, we have streak, and we have presence. This is it. This is all we need to track to win.

So let's just walk through these and really understand what these mean. This is how we know we're improving, right? It's not enough to vibe code to randomly ship a feature. That's cool. That's table stakes, right? That's, that's the low hanging fruit. We need to know we're improving. We need metrics. Right? If you don't measure it, you can't improve it.

So we want to increase size. We want to decrease attempts. We want to increase our streak and we want to decrease our presence. These four make up your Agentic Coding KPIs.

At the first level, we have size. We want to increase the size of work we can hand off to our Agentic Coding tools, to our agents. Okay. If you're improving, you'll be increasing the size of work, Right. So this means writing bigger plans and that means that your larger plans will likely consume more time, which will correlate to longer agent runs. Right. If you've been running five minute agentic jobs, right, where your agent goes off for five minutes and works on your codebase, that's good. We want that number to go up 10, 20, 30, an hour, three hours. Don't underestimate the amount of work you can hand off autonomously to your agent. So that's size. If you're improving, your agent decoding, this number goes up.

Now, of course, we have attempts. You know where this is going, right? We don't want issues. We don't want to miscommunicate. We don't want to have to go back in after the prompt completes and fix issues. This is attempts. You want to drive your attempts down. Why is that? It's because attempts, when you have to come back in, prompt again, correct the mistake, this costs your most important engineering resource your time. If your attempts are high in the five to 10 range, even the three to six range, you need to spend more time figuring out which of the 12 leverage points you're missing, okay? And you need to employ it, right? You need to use these leverage points.

Counterintuitively, iterating is not good. There are some cases When you're doing exploratory work, we're iterating is fine, but we're moving toward the space and the place where even iteration, right? Experimentation can be done with your agents. And that means you want fewer prompts. You want fewer attempts. We're not aiming to become a babysitter for AI agents. We're looking for one shot solutions.

Okay. You might be thinking, why is iterating so bad? The goal is to maximize what we can do with agentic coding, right? This is tactical Agentic Coding, not iterative prompting, right? Not iterative AI coding. This iterative back and forth, it's not very agentic, is it? We're not here to settle for what's easy. We're here to learn how to create self-operating codebases where agents operate on our behalf, all right?

That brings us to the next important KPI. These stack up on each other, as you can see, right? Streak. We want back to back to back one shot successes. Okay. We want one shot agent decoding prompts with zero issues. There's always kind of a balancing game, right? You want to keep increasing your size as you scale up. You might have to, you know, take a couple of attempts. That's fine. But what you want to do is get this to a point where you're running back to back to back successful agent decoding prompts that shipping real engineering work, right?

You want streaks of three, streaks of five, streaks of 10. An engineer that can run, you know, five one-shot agent decoding prompts that ship entire features, right? Back to back to back over and over drastically outperforms an engineer that runs five prompts, but had to fix three issues per prompts, right? That's three X slower, right? The goal here is simple. This KPI tracks one thing. Once you start one-shotting, don't break the streak. Keep that chain going. And when you break it, figure out exactly which leverage point you were missing. Because what we're gonna do here is hand all of this off to our agentic codebase, right? Our agents operating our code base. And we need them to be able to run reliably with extremely high accuracy, okay? This is what we're building up to.

The last is likely the most important. Presence you want to lower your presence to zero presence is a measure of how much you the engineer have to sit guide and correct your ai agent right now engineers are in fact operating with high presence we think that the end game of agentic coding is sitting here and prompting back and forth and back and forth right monitoring reviewing everything This is not the end game. This is the early game. With Agentic Coding, you can truly drop your presence to zero.

The balancing act here is learning what you can do with full autonomy, right? With the autonomy knob dialed up to 11. And it's knowing when there might be issues that you'll have to modify as you augment and automate the software developer lifecycle, okay? This is presence. It might seem crazy or realistic, depending on your experience level with Agentic coding, that's fine. Throughout TAC, throughout every single lesson you complete, you'll see that this is not only possible, but it's the future of engineering that you can pull into the present right now.

Okay, with each lesson you complete, this vision will become clearer and clearer to you. Okay, there's of course iteration along the way. Of course, as you scale up the size of your work, you'll have to put more attempts in, you'll break your streak, that's fine. We're gonna have high presence at the beginning, but the goal is that you have concrete KPIs you can drive down, you can drive to success, okay? This is Agentic Coding, this is tactical agentic coding, this is how we can know, right? Not guess, not vibe, this is how we know we're improving, all right?

There are ways to systematize this inside of applications, inside of GitHub or Jira or whatever you wanna use, but right now, all you need to do to be successful here throughout tactical Agentic Coding keep these numbers floating around your mind and know that you can use the 12 leverage points of Agentic Coding to take your agent's perspective to improve these kpis okay and step by step we're going to automate the software development life cycle you'll notice with all four of these kpis you can improve them all by using one or more of the 12 leverage points of agentic coding really four or more right because the core four are always there.

So, you know, for example, does your agent get confused because your codebase is using dictionaries instead of types, right? Obviously the clear answer there, leverage types to improve your agent performance, all right? Is your codebase structure inconsistent and confusing to navigate even for your team, right? Okay, refactor your codebase, build it for the new age of agents.

Are you still manually looking at error messages? Stop Stop. All right. We're first going to stop coding. But the next thing to do is stop looking at error messages. Right. Give them to your agent. And only when your agent fails do you take your precious time and dig into the error. All right. Make sure you have standard out logging that your agent can see all the time as much as possible. This will drop your attempts drastically.

OK. If you're running short back to back iterative prompts, stop, sit down, write some plans. Right. Be more detailed. You can plan with your agent as you'll see. In the next lesson, all right? Does your agent say it was successful? And then you see bugs when you run your application. You need tests. And as you're building up new features, as you're writing prompts, have your agent write tests as it goes, right? Your agent will automatically catch and fix issues because the output will go right to standard in, right? We can do that right now anywhere we want, PWD, bang, CD, app server bang UV run pie test.

Okay. And now the agent has all the tests, all the output, all the details, all the errors right in this context window. It can agentically solve this problem for you. Okay. Right tests. Are you running the same prompts, the same workflows over and over and over, right? For instance, we had our agent run our shell start command, right? Scripts start, copy this and literally tell your agent create dot clause slash command slash start and then as a string, just give it exactly what you want in there. Then you can reformat it later. Start with the bare minimum. Three time makes a pattern. Three time should trigger your engineering brain. Automate, right?

This is what prompt templates allow us to do. Automate work. Templates are big, big ideas we're gonna be looking at. Throughout Tactical agent coding right now we can boot up a new agent whenever we need to right Claude slash start. What do you know? Check this out. It's going to start the server and automatically listen to that input for however much time we give it right. Very important stuff there, right? So the examples here go on and on and on.

As you work through the 12 leverage points, you'll notice one tactic that summarizes it all. You must adopt your agent's perspective. This tactic will drive your success as an engineer that wields and deploys agents across your codebase. It's not about you anymore. It's about what you can do for your agent so they can work for you.

Okay? By adopting your agent's perspective, you do four things. You send the size of your agentic prompts up and the size of work you can do up. You send your attempts down to one per prompt. You increase your streak so you can chain together success so you can drop your presence down to zero.

Okay, I hope you can start to see the vision of engineering we're creating, the vision of Agentic Engineering we're creating. With this critical tactic, And these 12 leverage points, you can start rapidly improving your agent to coding performance.

Now there's something important to call out before we move on to lesson three. We're leaving the beginner lessons and moving into the intermediate zone. We have to call this out. We've been using Claude Code in phase one mode. Okay, as I mentioned, we've been prompting back and forth very iteratively. This tanks our presence KPI, right? It literally drives it up every interaction increases your presence.

As we progress throughout TAC, we'll be using this mode right here, programmable mode. We'll be using Claude Code. We'll be using AI agents to do engineering work autonomously. This will be uncomfortable. As us engineers, we love control and visibility, but it's time for us to let that go. In order to let our code base run itself, we have to let go of control. We still need to know exactly what's happening. We still need to be able to observe, but we need to let go of the hands-on engineering, right? We have to stop coding.

This is going to be hard. The hardest thing we do in tactical agentic coding is transition away from AI coding and even further away from manual coding. The new age phase two engineering looks less and less of what it used to look like. What does stay is architecture. What does stay is direction. It's planning. It's thinking. It's engineering. It's building out to create value, right? This is all about our products and our products are all about our users. Okay. Never lose sight of that throughout every lesson, throughout all the noise, bring it all back to what this is all for. We're scaling up what we can do. Once again, we're going up the abstraction chain.

Once again, English is the new programming language and we're just digging into that fact and we're taking it where it's going before it gets there. Okay? These leverage points, the largest consistent impact on your ability to create engineering results with one-shot agentic prompts now this is important if you want to create powerful sets of agents and deploy them across the software development life cycle like we're aiming to do we must know how to fire off a single powerful agent running a single prompt right remember Big things are just two or more small things put together. If you do the simple thing well, you will be able to scale it into something valuable. Master the primitives and you'll master the compositions.

As we work through each lesson, we're not coding anymore. We're adopting our agent's perspective. We're leaning in to the autonomy. This enables us to give our agents the leverage points it needs to ship engineering work on our behalf.

Now we've glossed over a couple of leverage points because they're so powerful, they deserve their own lesson and notice how some of the leverage points are the node in the software developer lifecycle. Okay. In lesson three, we'll focus our attention on one of the most powerful leverage points, the plan. You'll learn to use meta prompting. We'll use higher order prompts and we'll build reusable plans that you're agent can use to transform your high level prompt into low level accurate codebase details that will increase your KPIs, right? Your key performance indicators. You'll learn how to write plans from your agent's perspective, plans that are so clear success becomes inevitable.

Great work here. You've got the momentum rolling toward the future of Agentic Coding. I'll see you in lesson three.
